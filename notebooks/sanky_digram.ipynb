{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corpus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vsm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# print the number of topics in the first model\n",
    "print topic_range[0]\n",
    "# remember that list indexes start with 0 not 1!\n",
    "\n",
    "# replace 'topic_range[0]' with a specific number, if you like\n",
    "k = topic_range[0]\n",
    "\n",
    "# load the topic model\n",
    "v = lda_v[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the number of words printed per topic, use the `print_len` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 6, 4, 12, 13, 5, 15, 1, 19, 17]\n"
     ]
    }
   ],
   "source": [
    "top10topics = []\n",
    "top10topicsweight = []\n",
    "for a in v.aggregate_doc_topics(v.labels[:], normed_sum=True):\n",
    "    top10topics.append(a[0])\n",
    "    top10topicsweight.append(a[1])\n",
    "print top10topics[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'color': '1', 'depth': '0', 'name': 'T8', 'weight': 0.10558674}, {'color': '1', 'depth': '0', 'name': 'T6', 'weight': 0.094769537}, {'color': '1', 'depth': '0', 'name': 'T4', 'weight': 0.072251268}, {'color': '1', 'depth': '0', 'name': 'T12', 'weight': 0.060897022}, {'color': '1', 'depth': '0', 'name': 'T13', 'weight': 0.05996285}, {'color': '1', 'depth': '0', 'name': 'T5', 'weight': 0.059090763}, {'color': '1', 'depth': '0', 'name': 'T15', 'weight': 0.056124251}, {'color': '1', 'depth': '0', 'name': 'T1', 'weight': 0.049529247}, {'color': '1', 'depth': '0', 'name': 'T19', 'weight': 0.049216188}, {'color': '1', 'depth': '0', 'name': 'T17', 'weight': 0.044962909}, {'color': '1', 'depth': '0', 'name': 'T9', 'weight': 0.043124355}, {'color': '1', 'depth': '0', 'name': 'T11', 'weight': 0.042134903}, {'color': '1', 'depth': '0', 'name': 'T2', 'weight': 0.039209232}, {'color': '1', 'depth': '0', 'name': 'T7', 'weight': 0.038921017}, {'color': '1', 'depth': '0', 'name': 'T18', 'weight': 0.037751071}, {'color': '1', 'depth': '0', 'name': 'T10', 'weight': 0.03548922}, {'color': '1', 'depth': '0', 'name': 'T3', 'weight': 0.034650903}, {'color': '1', 'depth': '0', 'name': 'T14', 'weight': 0.032119319}, {'color': '1', 'depth': '0', 'name': 'T16', 'weight': 0.023459909}, {'color': '1', 'depth': '0', 'name': 'T0', 'weight': 0.020749206}, {'color': '1', 'depth': '1', 'name': u'\\u6e05'}, {'color': '1', 'depth': '1', 'name': u'\\u968b'}, {'color': '1', 'depth': '1', 'name': u'\\u5357\\u5510'}, {'color': '1', 'depth': '1', 'name': u'\\u5317\\u5b8b'}, {'color': '1', 'depth': '1', 'name': u'\\u660e'}, {'color': '1', 'depth': '1', 'name': u'\\u5510'}, {'color': '1', 'depth': '1', 'name': u'\\u5357\\u9f50'}, {'color': '1', 'depth': '1', 'name': u'\\u4e1c\\u9b4f'}, {'color': '1', 'depth': '1', 'name': u'\\u4e1c\\u664b'}, {'color': '1', 'depth': '1', 'name': u'\\u4e1c\\u6c49'}, {'color': '1', 'depth': '1', 'name': u'\\u4e09\\u56fd'}, {'color': '1', 'depth': '1', 'name': u'\\u4e94\\u4ee3\\u5341\\u56fd'}, {'color': '1', 'depth': '1', 'name': u'\\u6c49'}, {'color': '1', 'depth': '1', 'name': u'\\u6218\\u56fd'}, {'color': '1', 'depth': '1', 'name': u'\\u5148\\u79e6'}, {'color': '1', 'depth': '1', 'name': u'\\u5b8b'}, {'color': '1', 'depth': '1', 'name': u'\\u5143'}, {'color': '1', 'depth': '1', 'name': u'\\u6625\\u79cb/\\u6218\\u56fd'}, {'color': '1', 'depth': '1', 'name': u'\\u897f\\u5468'}, {'color': '1', 'depth': '1', 'name': u'\\u5317\\u9b4f'}, {'color': '1', 'depth': '1', 'name': u'\\u6c11\\u56fd'}, {'color': '1', 'depth': '1', 'name': u'\\u660e\\u4ee3'}, {'color': '1', 'depth': '1', 'name': u'\\u5357\\u5b8b'}, {'color': '1', 'depth': '1', 'name': u'\\u9b4f'}, {'color': '1', 'depth': '1', 'name': u'\\u5317\\u9f50'}, {'color': '1', 'depth': '1', 'name': u'\\u9b4f\\u664b'}, {'color': '1', 'depth': '1', 'name': u'\\u6625\\u79cb\\u6218\\u56fd'}, {'color': '1', 'depth': '1', 'name': u'\\u6625\\u79cb'}, {'color': '1', 'depth': '1', 'name': u'\\u79e6'}, {'color': '1', 'depth': '1', 'name': u'\\u5357\\u5317\\u671d'}, {'color': '1', 'depth': '1', 'name': u'\\u5468'}, {'color': '1', 'depth': '1', 'name': u'\\u897f\\u664b'}, {'color': '1', 'depth': '1', 'name': u'\\u897f\\u6c49'}, {'color': '1', 'depth': '1', 'name': u'\\u79e6\\u6c49'}, {'color': '2', 'depth': '2', 'name': ''}]}\n"
     ]
    }
   ],
   "source": [
    "# depth 0\n",
    "\n",
    "handian = dict()\n",
    "handian['nodes']=[]\n",
    "\n",
    "for a in v.aggregate_doc_topics(v.labels[:], normed_sum=True):\n",
    "    temp = dict()\n",
    "    temp['color'] = '1'\n",
    "    temp['depth'] = '0'\n",
    "    temp['name'] = \"T%s\"%a[0]\n",
    "    temp['weight'] = a[1]\n",
    "    handian['nodes'].append(temp)\n",
    "# depth 1\n",
    "import csv\n",
    "import json\n",
    "\n",
    "csvfile = open('/home/hongliang/Downloads/mirrorfunctions/lib/test.csv','r')\n",
    "jsonfile = open('test.json','w')\n",
    "filednames = ('book','dynasty','year')\n",
    "reader = csv.DictReader(csvfile,filednames)\n",
    "dynasties = [row['dynasty'].decode('utf-8') for row in reader][1:]\n",
    "for a in set(dynasties):\n",
    "    temp = dict()\n",
    "    temp['color'] = '1'\n",
    "    temp['depth'] = '1'\n",
    "    temp['name'] = a\n",
    "    handian['nodes'].append(temp)\n",
    "\n",
    "    \n",
    "    \n",
    "# depth 2 folders name\n",
    "folders = set([])\n",
    "for label in v.labels[:]:\n",
    "    temp = ''\n",
    "    temp.join(label.split('/')[:-1])\n",
    "    folders.add(temp)\n",
    "    \n",
    "    \n",
    "for a in folders:\n",
    "    temp = dict()\n",
    "    temp['color'] = '2'\n",
    "    temp['depth'] = '2'\n",
    "    temp['name'] = a\n",
    "    handian['nodes'].append(temp)\n",
    "print handian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'mirrorfunctions\\u53f2\\u4e66\\u4e1c\\u89c2\\u6c49\\u8bb0\\u6821\\u6ce8': [197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222], u'mirrorfunctions\\u6cd5\\u5bb6\\u674e\\u65af\\u8c0f\\u9010\\u5ba2\\u4e66': [1555], u'mirrorfunctions\\u5112\\u5bb6\\u6625\\u79cb\\u7e41\\u9732': [1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279], u'mirrorfunctions\\u5112\\u5bb6\\u65b0\\u4e66': [1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130], u'mirrorfunctions\\u53f2\\u4e66\\u71d5\\u4e39\\u5b50': [570, 571, 572], u'mirrorfunctions\\u6cd5\\u5bb6\\u7ba1\\u5b50': [1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642], u'mirrorfunctions\\u5175\\u5bb6\\u53f8\\u9a6c\\u6cd5': [1498, 1499, 1500, 1501, 1502], u'mirrorfunctions\\u5112\\u5bb6\\u767d\\u864e\\u901a\\u4e49': [1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262], u'mirrorfunctions\\u533b\\u5b66\\u91d1\\u532e\\u8981\\u7565': [740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765], u'mirrorfunctions\\u53f2\\u4e66\\u6625\\u79cb\\u5de6\\u4f20': [469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483], u'mirrorfunctions\\u9053\\u5bb6\\u6587\\u5b50': [16], u'mirrorfunctions\\u53f2\\u4e66\\u524d\\u6c49\\u7eaa': [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u5468\\u6613': [988, 989, 990, 991, 992, 993, 994], u'mirrorfunctions\\u51fa\\u571f\\u6587\\u732e\\u90ed\\u5e97': [1769, 1770, 1771], u'mirrorfunctions\\u9053\\u5bb6\\u9053\\u5fb7\\u7ecf\\uff08\\u8001\\u5b50\\uff09': [13], u'mirrorfunctions\\u9053\\u5bb6\\u6587\\u59cb\\u771f\\u7ecf': [1, 2, 3, 4, 5, 6, 7, 8, 9], u'mirrorfunctions\\u9053\\u5bb6\\u9b3b\\u5b50': [0], u'mirrorfunctions\\u6cd5\\u5bb6\\u614e\\u5b50': [1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687], u'mirrorfunctions\\u5b57\\u4e66\\u8bf4\\u6587\\u89e3\\u5b57': [1101], u'mirrorfunctions\\u5112\\u5bb6\\u5b54\\u4e1b\\u5b50': [1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401], u'mirrorfunctions\\u5112\\u5bb6\\u8bba\\u8861': [1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u7126\\u6c0f\\u6613\\u6797': [923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986], u'mirrorfunctions\\u53f2\\u4e66\\u7a46\\u5929\\u5b50\\u4f20': [191, 192, 193, 194, 195, 196], u'mirrorfunctions\\u5175\\u5bb6\\u516d\\u97ec(\\u6ce8\\u91ca\\u672c)': [1504, 1505, 1506, 1507, 1508, 1509], u'mirrorfunctions\\u53f2\\u4e66\\u7af9\\u4e66\\u8bb0\\u5e74': [484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569], u'mirrorfunctions\\u9053\\u5bb6\\u9e56\\u51a0\\u5b50': [14], u'mirrorfunctions\\u53f2\\u4e66\\u6c49\\u4e66': [601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720], u'mirrorfunctions\\u5175\\u5bb6\\u4e09\\u7565': [1510, 1511, 1512], u'mirrorfunctions\\u53f2\\u4e66\\u53f2\\u8bb0': [327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u5c1a\\u4e66': [995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050], u'mirrorfunctions\\u5b57\\u4e66\\u6025\\u6551\\u7bc7': [1100], u'mirrorfunctions\\u533b\\u5b66\\u96be\\u7ecf': [731, 732, 733, 734, 735, 736, 737, 738, 739], u'mirrorfunctions\\u6742\\u5bb6\\u5c39\\u6587\\u5b50': [1750], u'mirrorfunctions\\u5175\\u5bb6\\u5c09\\u7f2d\\u5b50': [1503], u'mirrorfunctions\\u53f2\\u4e66\\u6625\\u79cb\\u8c37\\u6881\\u4f20': [269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280], u'mirrorfunctions\\u5112\\u5bb6\\u5927\\u6234\\u793c\\u8bb0': [1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169], u'mirrorfunctions\\u540d\\u5bb6\\u516c\\u5b59\\u9f99\\u5b50': [1120], u'mirrorfunctions\\u6cd5\\u5bb6\\u97e9\\u975e\\u5b50': [1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676], u'mirrorfunctions\\u5112\\u5bb6\\u7533\\u9274': [1476], u'mirrorfunctions\\u5175\\u5bb6\\u5b59\\u5b50\\u5175\\u6cd5': [1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497], u'mirrorfunctions\\u53f2\\u4e66\\u540e\\u6c49\\u4e66': [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], u'mirrorfunctions\\u53f2\\u4e66\\u6218\\u56fd\\u7b56': [233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268], u'mirrorfunctions\\u5112\\u5bb6\\u5b54\\u5b50\\u5bb6\\u8bed': [1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289], u'mirrorfunctions\\u9053\\u5bb6\\u5e84\\u5b50': [15], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u8bd7\\u7ecf': [1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080], u'mirrorfunctions\\u5112\\u5bb6\\u8bf4\\u82d1': [1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475], u'mirrorfunctions\\u53f2\\u4e66\\u9038\\u5468\\u4e66': [458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468], u'mirrorfunctions\\u58a8\\u5bb6\\u58a8\\u8fa9\\u6ce8\\u53d9': [1513], u'mirrorfunctions\\u5112\\u5bb6\\u65b0\\u5e8f': [1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299], u'mirrorfunctions\\u5175\\u5bb6\\u5434\\u5b50': [1479, 1480, 1481, 1482, 1483, 1484], u'mirrorfunctions\\u5112\\u5bb6\\u8bba\\u8bed': [1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322], u'mirrorfunctions\\u5112\\u5bb6\\u6f5c\\u592b\\u8bba': [1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220], u'mirrorfunctions\\u6742\\u5bb6\\u5415\\u6c0f\\u6625\\u79cb': [1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734], u'mirrorfunctions\\u53f2\\u4e66\\u56fd\\u8bed': [573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594], u'mirrorfunctions\\u53f2\\u4e66\\u664f\\u5b50\\u6625\\u79cb\\u96c6\\u91ca': [47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70], u'mirrorfunctions\\u7b97\\u4e66\\u5468\\u9ac0\\u7b97\\u7ecf': [1763], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u4eea\\u793c': [812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828], u'mirrorfunctions\\u58a8\\u5bb6\\u58a8\\u5b50': [1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528], u'mirrorfunctions\\u53f2\\u4e66\\u5217\\u5973\\u4f20': [320, 321, 322, 323, 324, 325, 326], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u5468\\u793c': [917, 918, 919, 920, 921, 922], u'mirrorfunctions\\u53f2\\u4e66\\u53e4\\u4e09\\u575f\\u5f62\\u575f': [296, 297, 298], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u4eac\\u6c0f\\u6613\\u4f20': [829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892], u'mirrorfunctions\\u5112\\u5bb6\\u592a\\u7384\\u7ecf': [1477, 1478], u'mirrorfunctions\\u53f2\\u4e66\\u6625\\u79cb\\u516c\\u7f8a\\u4f20': [281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292], u'mirrorfunctions\\u7b97\\u4e66\\u5b59\\u5b50\\u7b97\\u7ecf': [1765, 1766, 1767, 1768], u'mirrorfunctions\\u5b57\\u4e66\\u5c14\\u96c5': [1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099], u'mirrorfunctions\\u5112\\u5bb6\\u8340\\u5b50': [1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252], u'mirrorfunctions\\u5112\\u5bb6\\u4e2d\\u8bba': [1300, 1301, 1302], u'mirrorfunctions\\u53f2\\u4e66\\u897f\\u4eac\\u6742\\u8bb0': [595, 596, 597, 598, 599, 600], u'mirrorfunctions\\u53f2\\u4e66\\u8d8a\\u7edd\\u4e66': [303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u695a\\u8f9e\\u695a\\u8f9e': [987], u'mirrorfunctions\\u5112\\u5bb6\\u97e9\\u8bd7\\u5916\\u4f20': [1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332], u'mirrorfunctions\\u5b57\\u4e66\\u8f36\\u8f69\\u4f7f\\u8005\\u7edd\\u4ee3\\u8bed\\u91ca\\u522b\\u56fd\\u65b9\\u8a00': [1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119], u'mirrorfunctions\\u6cd5\\u5bb6\\u5546\\u541b\\u4e66': [1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554], u'mirrorfunctions\\u6cd5\\u5bb6\\u7533\\u4e0d\\u5bb3': [1677, 1678], u'mirrorfunctions\\u53f2\\u4e66\\u5434\\u8d8a\\u6625\\u79cb': [223, 224, 225, 226, 227, 228, 229, 230, 231, 232], u'mirrorfunctions\\u5112\\u5bb6\\u5b5f\\u5b50': [1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u5c71\\u6d77\\u7ecf': [794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811], u'mirrorfunctions\\u5112\\u5bb6\\u5b5d\\u7ecf': [1382], u'mirrorfunctions\\u6742\\u5bb6\\u9093\\u6790\\u5b50': [1747, 1748, 1749], u'mirrorfunctions\\u7b97\\u4e66\\u4e5d\\u7ae0\\u7b97\\u672f': [1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762], u'mirrorfunctions\\u533b\\u5b66\\u4f24\\u5bd2\\u8bba': [770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793], u'mirrorfunctions\\u6742\\u5bb6\\u6dee\\u5357\\u5b50': [1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708], u'mirrorfunctions\\u533b\\u5b66\\u9ec4\\u5e1d\\u5185\\u7ecf': [766, 767, 768, 769], u'mirrorfunctions\\u5b57\\u4e66\\u91ca\\u540d': [1102, 1103, 1104, 1105, 1106], u'mirrorfunctions\\u53f2\\u4e66\\u53e4\\u4e09\\u575f\\u5c71\\u575f': [299, 300, 301, 302], u'mirrorfunctions\\u5112\\u5bb6\\u98ce\\u4fd7\\u901a\\u4e49': [1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411], u'mirrorfunctions\\u51fa\\u571f\\u6587\\u732e\\u9a6c\\u738b\\u5806\\u8001\\u5b50B': [1772, 1773], u'mirrorfunctions\\u51fa\\u571f\\u6587\\u732e\\u9a6c\\u738b\\u5806\\u8001\\u5b50A': [1774, 1775], u'mirrorfunctions\\u53f2\\u4e66\\u76d0\\u94c1\\u8bba': [721, 722, 723, 724, 725, 726, 727, 728, 729, 730], u'mirrorfunctions\\u53f2\\u4e66\\u53e4\\u4e09\\u575f\\u6c14\\u575f': [293, 294, 295], u'mirrorfunctions\\u6742\\u5bb6\\u9b3c\\u8c37\\u5b50': [1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746], u'mirrorfunctions\\u9053\\u5bb6\\u6cb3\\u4e0a\\u516c': [10, 11], u'mirrorfunctions\\u7ecf\\u5178\\u6587\\u732e\\u8bd7\\u8bf4': [893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916], u'mirrorfunctions\\u5112\\u5bb6\\u793c\\u8bb0': [1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381], u'mirrorfunctions\\u7b97\\u4e66\\u6d77\\u5c9b\\u7b97\\u7ecf': [1764], u'mirrorfunctions\\u9053\\u5bb6\\u5217\\u5b50': [12], u'mirrorfunctions\\u5112\\u5bb6\\u626c\\u5b50\\u6cd5\\u8a00': [1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folders = set([])\n",
    "for label in v.labels[:]:\n",
    "    folders.add(''.join(label.split('/')[:-1]))\n",
    "folders_dict = dict([])\n",
    "for i in folders:\n",
    "    folders_dict[i] = []\n",
    "\n",
    "count = 0\n",
    "for label in v.labels[:]:\n",
    "    if ''.join(label.split('/')[:-1]) in folders:\n",
    "        temp = ''.join(label.split('/')[:-1])\n",
    "        folders_dict[temp].append(count)\n",
    "    count += 1\n",
    "print folders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "东汉 『史部』/载记/越绝书\n",
      "『史部』/载记/越绝书\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "u'\\u300e\\u53f2\\u90e8\\u300f/\\u8f7d\\u8bb0/\\u8d8a\\u7edd\\u4e66'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-6d97aacbda4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mhandian\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'\\u300e\\u53f2\\u90e8\\u300f/\\u8f7d\\u8bb0/\\u8d8a\\u7edd\\u4e66'"
     ]
    }
   ],
   "source": [
    "handian['links']=[]\n",
    "\n",
    "\n",
    "\n",
    "csvfile = open('/home/hongliang/Downloads/mirrorfunctions/lib/test.csv','r')\n",
    "jsonfile = open('test.json','w')\n",
    "filednames = ('book','dynasty','year')\n",
    "reader = csv.DictReader(csvfile,filednames)\n",
    "dynasties = [[row['dynasty'].decode('utf-8'),row['book'].decode('utf-8')] for row in reader][1:]\n",
    "for a in dynasties:\n",
    "    print a[0],'/'.join(a[1].strip(',').split('/'))\n",
    "    \n",
    "    temp = dict([])\n",
    "    temp['source'] = a[0]\n",
    "    temp['target'] = '/'.join(a[1].strip(',').split('/'))\n",
    "    print '/'.join(a[1].strip(',').split('/'))\n",
    "    temp['value'] = len(folders_dict['/'.join(a[1].strip(',').split('/'))])\n",
    "    handian['link'].append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Document-topic probabilities\n",
    "The above code shows the topic-word distributions and allows us to estimate the quality of our topics.\n",
    "\n",
    "#### `v.labels`\n",
    "The property `v.labels` (without parentheses) returns a list of all documents in a corpus, and is useful for processing each document generically, wihtout having to look up the identifiers on the file system.\n",
    "\n",
    "Below, we print the first 3 document labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mirrorfunctions/道家/鬻子/鬻子.txt\n",
      "mirrorfunctions/道家/文始真经/三极.txt\n",
      "mirrorfunctions/道家/文始真经/九药.txt\n"
     ]
    }
   ],
   "source": [
    "for label in v.labels[:3]:\n",
    "    print label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `v.doc_topics(doc_or_docs)`\n",
    "Each document-topic distribution can be examined with `v.doc_topics()`, which takes as its argument either a single label or a list of labels. Below we view the distribution for the first 3 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th style=\"text-align: center; background: #A9D0F5;            fontsize: 14px;\" colspan=\"6\"> Distributions over Topics </th></tr><tr><th style=\"text-align: center; background: #CEE3F6;\"                 colspan=\"2\">Doc: mirrorfunctions/兵家/司马法/仁本第一.txt</th><th style=\"text-align: center; background: #CEE3F6;\"                 colspan=\"2\">Doc: mirrorfunctions/兵家/司马法/定爵第三.txt</th><th style=\"text-align: center; background: #CEE3F6;\"                 colspan=\"2\">Doc: mirrorfunctions/兵家/司马法/天子之义第二.txt</th></tr><tr><th style=\"text-align: center; background: #EFF2FB;\">                        Topic</th><th style=\"text-align: center; background: #EFF2FB;\">                        Prob</th><th style=\"text-align: center; background: #EFF2FB;\">                        Topic</th><th style=\"text-align: center; background: #EFF2FB;\">                        Prob</th><th style=\"text-align: center; background: #EFF2FB;\">                        Topic</th><th style=\"text-align: center; background: #EFF2FB;\">                        Prob</th></tr><tr><td>47</td><td>0.29000</td><td>58</td><td>0.19810</td><td>47</td><td>0.23848</td></tr><tr><td>61</td><td>0.24935</td><td>47</td><td>0.18848</td><td>58</td><td>0.15771</td></tr><tr><td>79</td><td>0.11114</td><td>61</td><td>0.17887</td><td>61</td><td>0.14233</td></tr><tr><td>58</td><td>0.07591</td><td>67</td><td>0.11733</td><td>36</td><td>0.10387</td></tr><tr><td>85</td><td>0.05694</td><td>21</td><td>0.05963</td><td>67</td><td>0.08271</td></tr><tr><td>32</td><td>0.05423</td><td>9</td><td>0.05579</td><td>89</td><td>0.07117</td></tr><tr><td>21</td><td>0.05423</td><td>89</td><td>0.05194</td><td>98</td><td>0.05963</td></tr><tr><td>20</td><td>0.03797</td><td>44</td><td>0.04425</td><td>70</td><td>0.05963</td></tr><tr><td>36</td><td>0.03526</td><td>85</td><td>0.03656</td><td>82</td><td>0.04810</td></tr><tr><td>97</td><td>0.01629</td><td>4</td><td>0.02694</td><td>85</td><td>0.02887</td></tr></table>"
      ],
      "text/plain": [
       "[LabeledColumn([(47, 0.28999972343444824), (61, 0.24934932589530945),\n",
       "        (79, 0.11113809794187546), (58, 0.07590778172016144),\n",
       "        (85, 0.05693761259317398), (32, 0.054227590560913086),\n",
       "        (21, 0.054227590560913086), (20, 0.037967439740896225),\n",
       "        (36, 0.03525742143392563), (97, 0.016287250444293022),\n",
       "        (34, 0.016287246719002724), (92, 2.7106030756840482e-05),\n",
       "        (31, 2.7106030756840482e-05), (94, 2.7106030756840482e-05),\n",
       "        (70, 2.7106030756840482e-05), (67, 2.7106030756840482e-05),\n",
       "        (82, 2.7106030756840482e-05), (16, 2.7106030756840482e-05),\n",
       "        (30, 2.710086300794501e-05), (33, 2.710086300794501e-05),\n",
       "        (99, 2.710086300794501e-05), (35, 2.710086300794501e-05),\n",
       "        (37, 2.710086300794501e-05), (38, 2.710086300794501e-05),\n",
       "        (39, 2.710086300794501e-05), (41, 2.710086300794501e-05),\n",
       "        (42, 2.710086300794501e-05), (43, 2.710086300794501e-05),\n",
       "        (44, 2.710086300794501e-05), (45, 2.710086300794501e-05),\n",
       "        (29, 2.710086300794501e-05), (24, 2.710086300794501e-05),\n",
       "        (28, 2.710086300794501e-05), (27, 2.710086300794501e-05),\n",
       "        (1, 2.710086300794501e-05), (2, 2.710086300794501e-05),\n",
       "        (3, 2.710086300794501e-05), (5, 2.710086300794501e-05),\n",
       "        (6, 2.710086300794501e-05), (7, 2.710086300794501e-05),\n",
       "        (9, 2.710086300794501e-05), (10, 2.710086300794501e-05),\n",
       "        (12, 2.710086300794501e-05), (13, 2.710086300794501e-05),\n",
       "        (15, 2.710086300794501e-05), (17, 2.710086300794501e-05),\n",
       "        (18, 2.710086300794501e-05), (19, 2.710086300794501e-05),\n",
       "        (22, 2.710086300794501e-05), (25, 2.710086300794501e-05),\n",
       "        (26, 2.710086300794501e-05), (46, 2.710086300794501e-05),\n",
       "        (0, 2.710086300794501e-05), (48, 2.710086300794501e-05),\n",
       "        (75, 2.710086300794501e-05), (90, 2.710086300794501e-05),\n",
       "        (71, 2.710086300794501e-05), (72, 2.710086300794501e-05),\n",
       "        (73, 2.710086300794501e-05), (89, 2.710086300794501e-05),\n",
       "        (74, 2.710086300794501e-05), (76, 2.710086300794501e-05),\n",
       "        (87, 2.710086300794501e-05), (77, 2.710086300794501e-05),\n",
       "        (78, 2.710086300794501e-05), (80, 2.710086300794501e-05),\n",
       "        (81, 2.710086300794501e-05), (88, 2.710086300794501e-05),\n",
       "        (84, 2.710086300794501e-05), (68, 2.710086300794501e-05),\n",
       "        (66, 2.710086300794501e-05), (65, 2.710086300794501e-05),\n",
       "        (64, 2.710086300794501e-05), (96, 2.710086300794501e-05),\n",
       "        (51, 2.710086300794501e-05), (52, 2.710086300794501e-05),\n",
       "        (53, 2.710086300794501e-05), (95, 2.710086300794501e-05),\n",
       "        (54, 2.710086300794501e-05), (86, 2.710086300794501e-05),\n",
       "        (56, 2.710086300794501e-05), (57, 2.710086300794501e-05),\n",
       "        (59, 2.710086300794501e-05), (62, 2.710086300794501e-05),\n",
       "        (91, 2.710086300794501e-05), (4, 2.7100215447717346e-05),\n",
       "        (8, 2.7100215447717346e-05), (93, 2.7100215447717346e-05),\n",
       "        (23, 2.7100215447717346e-05), (11, 2.7100215447717346e-05),\n",
       "        (14, 2.7100215447717346e-05), (83, 2.7100215447717346e-05),\n",
       "        (98, 2.7100215447717346e-05), (69, 2.7100215447717346e-05),\n",
       "        (63, 2.7100215447717346e-05), (60, 2.7100215447717346e-05),\n",
       "        (55, 2.7100215447717346e-05), (40, 2.7100215447717346e-05),\n",
       "        (50, 2.7100215447717346e-05), (49, 2.7100215447717346e-05)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')]),\n",
       " LabeledColumn([(58, 0.19809600710868835), (47, 0.18848063051700592),\n",
       "        (61, 0.1788652390241623), (67, 0.11732683330774307),\n",
       "        (21, 0.05963458493351936), (9, 0.05578843504190445),\n",
       "        (89, 0.05194227024912834), (44, 0.044249966740608215),\n",
       "        (85, 0.03655766695737839), (4, 0.026942286640405655),\n",
       "        (96, 0.019249984994530678), (46, 0.0115576833486557),\n",
       "        (51, 0.007711532525718212), (57, 0.0019423060584813356),\n",
       "        (39, 1.9234861611039378e-05), (16, 1.9234861611039378e-05),\n",
       "        (31, 1.9234861611039378e-05), (30, 1.9234861611039378e-05),\n",
       "        (82, 1.9234861611039378e-05), (37, 1.9231192709412426e-05),\n",
       "        (38, 1.9231192709412426e-05), (49, 1.9231192709412426e-05),\n",
       "        (40, 1.9231192709412426e-05), (41, 1.9231192709412426e-05),\n",
       "        (42, 1.9231192709412426e-05), (35, 1.9231192709412426e-05),\n",
       "        (43, 1.9231192709412426e-05), (48, 1.9231192709412426e-05),\n",
       "        (36, 1.9231192709412426e-05), (28, 1.9231192709412426e-05),\n",
       "        (34, 1.9231192709412426e-05), (17, 1.9231192709412426e-05),\n",
       "        (3, 1.9231192709412426e-05), (5, 1.9231192709412426e-05),\n",
       "        (7, 1.9231192709412426e-05), (8, 1.9231192709412426e-05),\n",
       "        (10, 1.9231192709412426e-05), (13, 1.9231192709412426e-05),\n",
       "        (18, 1.9231192709412426e-05), (33, 1.9231192709412426e-05),\n",
       "        (20, 1.9231192709412426e-05), (22, 1.9231192709412426e-05),\n",
       "        (24, 1.9231192709412426e-05), (26, 1.9231192709412426e-05),\n",
       "        (27, 1.9231192709412426e-05), (32, 1.9231192709412426e-05),\n",
       "        (98, 1.9231192709412426e-05), (0, 1.9231192709412426e-05),\n",
       "        (73, 1.9231192709412426e-05), (97, 1.9231192709412426e-05),\n",
       "        (95, 1.9231192709412426e-05), (76, 1.9231192709412426e-05),\n",
       "        (77, 1.9231192709412426e-05), (78, 1.9231192709412426e-05),\n",
       "        (94, 1.9231192709412426e-05), (79, 1.9231192709412426e-05),\n",
       "        (80, 1.9231192709412426e-05), (81, 1.9231192709412426e-05),\n",
       "        (83, 1.9231192709412426e-05), (93, 1.9231192709412426e-05),\n",
       "        (84, 1.9231192709412426e-05), (86, 1.9231192709412426e-05),\n",
       "        (92, 1.9231192709412426e-05), (91, 1.9231192709412426e-05),\n",
       "        (90, 1.9231192709412426e-05), (75, 1.9231192709412426e-05),\n",
       "        (88, 1.9231192709412426e-05), (63, 1.9231192709412426e-05),\n",
       "        (55, 1.9231192709412426e-05), (71, 1.9231192709412426e-05),\n",
       "        (70, 1.9231192709412426e-05), (69, 1.9231192709412426e-05),\n",
       "        (68, 1.9231192709412426e-05), (66, 1.9231192709412426e-05),\n",
       "        (65, 1.9231192709412426e-05), (64, 1.9231192709412426e-05),\n",
       "        (53, 1.9231192709412426e-05), (72, 1.9231192709412426e-05),\n",
       "        (62, 1.9231192709412426e-05), (54, 1.9231192709412426e-05),\n",
       "        (59, 1.9231192709412426e-05), (56, 1.9231192709412426e-05),\n",
       "        (1, 1.9230752513976768e-05), (11, 1.9230734324082732e-05),\n",
       "        (2, 1.9230734324082732e-05), (6, 1.9230734324082732e-05),\n",
       "        (52, 1.9230734324082732e-05), (25, 1.9230734324082732e-05),\n",
       "        (12, 1.9230734324082732e-05), (14, 1.9230734324082732e-05),\n",
       "        (15, 1.9230734324082732e-05), (87, 1.9230734324082732e-05),\n",
       "        (19, 1.9230734324082732e-05), (23, 1.9230734324082732e-05),\n",
       "        (50, 1.9230734324082732e-05), (29, 1.9230734324082732e-05),\n",
       "        (74, 1.9230734324082732e-05), (60, 1.9230734324082732e-05),\n",
       "        (45, 1.9230734324082732e-05), (99, 1.9230734324082732e-05)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')]),\n",
       " LabeledColumn([(47, 0.2384806126356125), (58, 0.1577114462852478),\n",
       "        (61, 0.14232684671878815), (36, 0.10386531800031662),\n",
       "        (67, 0.08271149545907974), (89, 0.0711730346083641),\n",
       "        (98, 0.059634577482938766), (70, 0.059634577482938766),\n",
       "        (82, 0.048096124082803726), (85, 0.02886536903679371),\n",
       "        (41, 0.0057884580455720425), (83, 1.923486343002878e-05),\n",
       "        (51, 1.923486343002878e-05), (13, 1.923486343002878e-05),\n",
       "        (79, 1.923486343002878e-05), (0, 1.923486343002878e-05),\n",
       "        (31, 1.923486343002878e-05), (1, 1.923486343002878e-05),\n",
       "        (26, 1.923486343002878e-05), (15, 1.923486343002878e-05),\n",
       "        (45, 1.9231196347391233e-05), (53, 1.9231196347391233e-05),\n",
       "        (20, 1.9231196347391233e-05), (52, 1.9231196347391233e-05),\n",
       "        (21, 1.9231196347391233e-05), (22, 1.9231196347391233e-05),\n",
       "        (50, 1.9231196347391233e-05), (23, 1.9231196347391233e-05),\n",
       "        (48, 1.9231196347391233e-05), (25, 1.9231196347391233e-05),\n",
       "        (46, 1.9231196347391233e-05), (10, 1.9231196347391233e-05),\n",
       "        (43, 1.9231196347391233e-05), (42, 1.9231196347391233e-05),\n",
       "        (27, 1.9231196347391233e-05), (12, 1.9231196347391233e-05),\n",
       "        (38, 1.9231196347391233e-05), (37, 1.9231196347391233e-05),\n",
       "        (9, 1.9231196347391233e-05), (28, 1.9231196347391233e-05),\n",
       "        (16, 1.9231196347391233e-05), (33, 1.9231196347391233e-05),\n",
       "        (32, 1.9231196347391233e-05), (54, 1.9231196347391233e-05),\n",
       "        (59, 1.9231196347391233e-05), (56, 1.9231196347391233e-05),\n",
       "        (4, 1.9231196347391233e-05), (97, 1.9231196347391233e-05),\n",
       "        (96, 1.9231196347391233e-05), (95, 1.9231196347391233e-05),\n",
       "        (94, 1.9231196347391233e-05), (93, 1.9231196347391233e-05),\n",
       "        (91, 1.9231196347391233e-05), (90, 1.9231196347391233e-05),\n",
       "        (88, 1.9231196347391233e-05), (2, 1.9231196347391233e-05),\n",
       "        (84, 1.9231196347391233e-05), (81, 1.9231196347391233e-05),\n",
       "        (80, 1.9231196347391233e-05), (78, 1.9231196347391233e-05),\n",
       "        (57, 1.9231196347391233e-05), (77, 1.9231196347391233e-05),\n",
       "        (5, 1.9231196347391233e-05), (74, 1.9231196347391233e-05),\n",
       "        (18, 1.9231196347391233e-05), (8, 1.9231196347391233e-05),\n",
       "        (62, 1.9231196347391233e-05), (63, 1.9231196347391233e-05),\n",
       "        (7, 1.9231196347391233e-05), (65, 1.9231196347391233e-05),\n",
       "        (66, 1.9231196347391233e-05), (6, 1.9231196347391233e-05),\n",
       "        (69, 1.9231196347391233e-05), (71, 1.9231196347391233e-05),\n",
       "        (72, 1.9231196347391233e-05), (73, 1.9231196347391233e-05),\n",
       "        (19, 1.9231196347391233e-05), (3, 1.923073796206154e-05),\n",
       "        (17, 1.923073796206154e-05), (14, 1.923073796206154e-05),\n",
       "        (11, 1.923073796206154e-05), (99, 1.923073796206154e-05),\n",
       "        (24, 1.923073796206154e-05), (29, 1.923073796206154e-05),\n",
       "        (92, 1.923073796206154e-05), (87, 1.923073796206154e-05),\n",
       "        (86, 1.923073796206154e-05), (76, 1.923073796206154e-05),\n",
       "        (75, 1.923073796206154e-05), (68, 1.923073796206154e-05),\n",
       "        (64, 1.923073796206154e-05), (60, 1.923073796206154e-05),\n",
       "        (55, 1.923073796206154e-05), (44, 1.923073796206154e-05),\n",
       "        (40, 1.923073796206154e-05), (39, 1.923073796206154e-05),\n",
       "        (35, 1.923073796206154e-05), (34, 1.923073796206154e-05),\n",
       "        (30, 1.923073796206154e-05), (49, 1.923073796206154e-05)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.doc_topics(v.labels[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `v.aggregate_doc_topics(doc_or_docs, normed_sum=False)`\n",
    "While `v.doc_topics(doc_or_docs)` shows the distribution for each document, `v.aggregate_doc_topics()` shows the average distribution of a collection of documents. The `normed` argument tells the program whether to weight each document by its length (`normed_sum=True`) or to consider them all equally (`normed_sum=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan                    =\"2\">Aggregate Distribution over Topics</th></tr><tr><th style=\"text-align: center; background: #EFF2FB; \">Topic                          </th><th style=\"text-align: center; background: #EFF2FB; \">Prob                          </th></tr><tr><td>47                                     </td><td>0.23899                                </td></tr><tr><td>61                                     </td><td>0.19018                                </td></tr><tr><td>58                                     </td><td>0.14391                                </td></tr><tr><td>67                                     </td><td>0.06669                                </td></tr><tr><td>36                                     </td><td>0.04638                                </td></tr><tr><td>89                                     </td><td>0.04105                                </td></tr><tr><td>85                                     </td><td>0.04079                                </td></tr><tr><td>21                                     </td><td>0.03796                                </td></tr><tr><td>79                                     </td><td>0.03706                                </td></tr><tr><td>70                                     </td><td>0.01989                                </td></tr></table>"
      ],
      "text/plain": [
       "LabeledColumn([(47, 0.23898716270923615), (61, 0.19018059968948364),\n",
       "       (58, 0.14390519261360168), (67, 0.06668852269649506),\n",
       "       (36, 0.04638069123029709), (89, 0.04104749858379364),\n",
       "       (85, 0.04078691080212593), (21, 0.03796049579977989),\n",
       "       (79, 0.03705888241529465), (70, 0.019893653690814972),\n",
       "       (98, 0.019893649965524673), (9, 0.0186116024851799),\n",
       "       (32, 0.018088696524500847), (82, 0.01604750007390976),\n",
       "       (44, 0.014765443280339241), (20, 0.012668642215430737),\n",
       "       (4, 0.008996212854981422), (96, 0.006432110909372568),\n",
       "       (97, 0.005441908724606037), (34, 0.005441906861960888),\n",
       "       (46, 0.0038680077996104956), (51, 0.0025859579909592867),\n",
       "       (41, 0.0019449313404038548), (57, 0.0006628797855228186),\n",
       "       (31, 2.185860284953378e-05), (16, 2.18573804886546e-05),\n",
       "       (94, 2.1856156308786012e-05), (92, 2.1856003513676114e-05),\n",
       "       (13, 2.1855654267710634e-05), (26, 2.1855654267710634e-05),\n",
       "       (0, 2.1855654267710634e-05), (1, 2.185550874855835e-05),\n",
       "       (39, 2.185550329159014e-05), (30, 2.185550329159014e-05),\n",
       "       (15, 2.185550329159014e-05), (83, 2.1855439626961015e-05),\n",
       "       (22, 2.185443190683145e-05), (90, 2.185443190683145e-05),\n",
       "       (80, 2.185443190683145e-05), (43, 2.185443190683145e-05),\n",
       "       (42, 2.185443190683145e-05), (81, 2.185443190683145e-05),\n",
       "       (5, 2.185443190683145e-05), (37, 2.185443190683145e-05),\n",
       "       (38, 2.185443190683145e-05), (88, 2.185443190683145e-05),\n",
       "       (7, 2.185443190683145e-05), (84, 2.185443190683145e-05),\n",
       "       (33, 2.185443190683145e-05), (28, 2.185443190683145e-05),\n",
       "       (78, 2.185443190683145e-05), (77, 2.185443190683145e-05),\n",
       "       (48, 2.185443190683145e-05), (73, 2.185443190683145e-05),\n",
       "       (66, 2.185443190683145e-05), (65, 2.185443190683145e-05),\n",
       "       (95, 2.185443190683145e-05), (62, 2.185443190683145e-05),\n",
       "       (71, 2.185443190683145e-05), (59, 2.185443190683145e-05),\n",
       "       (91, 2.185443190683145e-05), (72, 2.185443190683145e-05),\n",
       "       (56, 2.185443190683145e-05), (10, 2.185443190683145e-05),\n",
       "       (54, 2.185443190683145e-05), (53, 2.185443190683145e-05),\n",
       "       (18, 2.185443190683145e-05), (27, 2.185443190683145e-05),\n",
       "       (17, 2.1854280930710956e-05), (24, 2.1854280930710956e-05),\n",
       "       (12, 2.1854280930710956e-05), (25, 2.1854280930710956e-05),\n",
       "       (19, 2.1854280930710956e-05), (68, 2.1854280930710956e-05),\n",
       "       (6, 2.1854280930710956e-05), (86, 2.1854280930710956e-05),\n",
       "       (35, 2.1854280930710956e-05), (45, 2.1854280930710956e-05),\n",
       "       (76, 2.1854280930710956e-05), (75, 2.1854280930710956e-05),\n",
       "       (74, 2.1854280930710956e-05), (52, 2.1854280930710956e-05),\n",
       "       (2, 2.1854280930710956e-05), (64, 2.1854280930710956e-05),\n",
       "       (3, 2.1854280930710956e-05), (69, 2.1854217266081832e-05),\n",
       "       (93, 2.1854217266081832e-05), (8, 2.1854217266081832e-05),\n",
       "       (63, 2.1854217266081832e-05), (99, 2.1854126316611655e-05),\n",
       "       (29, 2.1854126316611655e-05), (87, 2.1854126316611655e-05),\n",
       "       (23, 2.185406265198253e-05), (40, 2.185406265198253e-05),\n",
       "       (50, 2.185406265198253e-05), (55, 2.185406265198253e-05),\n",
       "       (49, 2.185406265198253e-05), (11, 2.1853911675862037e-05),\n",
       "       (14, 2.1853911675862037e-05), (60, 2.1853911675862037e-05)], \n",
       "      dtype=[('i', '<i8'), ('value', '<f4')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.aggregate_doc_topics(v.labels[:3], normed_sum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing documents with `v.dist()`\n",
    "\n",
    "Topic models give us a way to compare the siimilarity between two documents. To do this, we use `v.dist()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57981946672305495"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.dist(v.labels[0], v.labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative distance measures\n",
    "By default, the Topic Explorer uses the Jensen-Shannon Distance to calculate the distance between documents. The Jensen-Shannon Distance (JSD) is a symmetric measure based on information theory that characterizes the difference between two probability distributions.\n",
    "\n",
    "However, several alternate methods are built into the `vsm.spatial` module. These include the Kullbeck-Liebler Divergence, which is an asymmetric component of the JSD and is used in [Murdock et al. (in review)](http://arxiv.org/abs/1509.07175) to characterize the cognitive surprise of a new text, given previous texts.\n",
    "\n",
    "Rather than using the JSD and assuming symmetric divergence between items, we assume that the second document is encountered after the first, effectively measuring text-to-text divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First to second 3.34743666971\n",
      "Second to first 3.7504995194\n"
     ]
    }
   ],
   "source": [
    "# first import KL divergence:\n",
    "from vsm.spatial import KL_div\n",
    "\n",
    "# calculate KL divergence from the first document to the second\n",
    "print \"First to second\", v.dist(v.labels[0], v.labels[1], dist_fn=KL_div)\n",
    "\n",
    "# calculate KL divergence from the second document to the first, highlighting asymmetry:\n",
    "print \"Second to first\", v.dist(v.labels[1], v.labels[0], dist_fn=KL_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python's Help System\n",
    "\n",
    "There are many other functions in the InPhO Topic Explorer and the associated `vsm` library. These are extensively documented within the code. \n",
    "\n",
    "One little-known feature about Python is its capacity for introspection: by using the `help()` method, one can find out all methods and properties of an object. For example, if one wanted to know what methods could be called on their corpus object, you could run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Corpus in module vsm.corpus.base object:\n",
      "\n",
      "class Corpus(BaseCorpus)\n",
      " |  The goal of the Corpus class is to provide an efficient representation    of a textual corpus.\n",
      " |  \n",
      " |  A Corpus object contains an integer representation of the text and\n",
      " |  maps to permit conversion between integer and string\n",
      " |  representations of a given word.\n",
      " |  \n",
      " |  As a BaseCorpus object, it includes a dictionary of tokenizations\n",
      " |  of the corpus and a method for viewing (without copying) these\n",
      " |  tokenizations. This dictionary also stores metadata (e.g.,\n",
      " |  document names) associated with the available tokenizations.\n",
      " |  \n",
      " |  :param corpus: A string array representing the corpus as a sequence of\n",
      " |      atomic words.\n",
      " |  :type corpus: array-like\n",
      " |  \n",
      " |  :param context_data: Each element in `context_data` is an array containing \n",
      " |      the indices marking the token boundaries. An element in `context_data` is\n",
      " |      intended for use as a value for the `indices_or_sections`\n",
      " |      parameter in `numpy.split`. Elements of `context_data` may also be\n",
      " |      1-D arrays whose elements are pairs, where the first element\n",
      " |      is a context boundary and the second element is metadata\n",
      " |      associated with that context preceding that boundary. For\n",
      " |      example, (250, 'dogs') might indicate that the 'article' context\n",
      " |      ending at the 250th word of the corpus is named 'dogs'.\n",
      " |      Default is `None`.\n",
      " |  :type context_data: list-like with 1-D integer array-like elements, optional\n",
      " |  \n",
      " |  :param context_types: Each element in `context_types` is a type of a context\n",
      " |      in `context_data`.\n",
      " |  :type context_types: array-like, optional\n",
      " |  \n",
      " |  :attributes: \n",
      " |      * **corpus** (1-D 32-bit integer array)\n",
      " |          corpus is the integer representation of the input string array-like\n",
      " |          value of the corpus parameter\n",
      " |      * **words** (1-D string array)\n",
      " |          The indexed set of strings occurring in corpus. It is a string-typed array.\n",
      " |      * **words_in** (1-D 32-bit integer dictionary)\n",
      " |          A dictionary whose keys are `words` and whose values are their \n",
      " |          corresponding integers (i.e., indices in `words`).\n",
      " |      \n",
      " |  :methods:\n",
      " |      * **view_metadata**\n",
      " |          Takes a type of tokenization and returns a view of the metadata\n",
      " |          of the tokenization.\n",
      " |      * **view_contexts**\n",
      " |          Takes a type of tokenization and returns a view of the corpus tokenized\n",
      " |          accordingly. The optional parameter `strings` takes a boolean value: \n",
      " |          True to view string representations of words; False to view integer \n",
      " |          representations of words. Default is `False`.\n",
      " |      * **save**\n",
      " |          Takes a filename and saves the data contained in a Corpus object to \n",
      " |          a `npy` file using `numpy.savez`.\n",
      " |      * **load**\n",
      " |          Static method. Takes a filename, loads the file data into a Corpus\n",
      " |          object and returns the object.\n",
      " |      * **apply_stoplist**\n",
      " |          Takes a list of stopwords and returns a copy of the corpus with \n",
      " |          the stopwords removed.\n",
      " |      * **tolist**\n",
      " |          Returns Corpus object as a list of lists of either integers or strings, \n",
      " |          according to `as_strings`.\n",
      " |      \n",
      " |  :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  **Examples**\n",
      " |  \n",
      " |  >>> text = ['I', 'came', 'I', 'saw', 'I', 'conquered']\n",
      " |  >>> context_types = ['sentences']\n",
      " |  >>> context_data = [np.array([(2, 'Veni'), (4, 'Vidi'), (6, 'Vici')],\n",
      " |                          dtype=[('idx', '<i8'), ('sent_label', '|S6')])]\n",
      " |  \n",
      " |  >>> from vsm.corpus import Corpus\n",
      " |  >>> c = Corpus(text, context_types=context_types, context_data=context_data)\n",
      " |  >>> c.corpus\n",
      " |  array([0, 1, 0, 2, 0, 3], dtype=int32)\n",
      " |  \n",
      " |  >>> c.words\n",
      " |  array(['I', 'came', 'saw', 'conquered'],\n",
      " |        dtype='|S9')\n",
      " |  \n",
      " |  >>> c.words_int['saw']\n",
      " |  2\n",
      " |  \n",
      " |  >>> c.view_contexts('sentences')\n",
      " |  [array([0, 3], dtype=int32), array([0, 2], dtype=int32),\n",
      " |   array([0, 1], dtype=int32)]\n",
      " |  \n",
      " |  >>> c.view_contexts('sentences', as_strings=True)\n",
      " |  [array(['I', 'came'], \n",
      " |        dtype='|S9'),\n",
      " |   array(['I', 'saw'], \n",
      " |        dtype='|S9'),\n",
      " |   array(['I', 'conquered'], \n",
      " |        dtype='|S9')]\n",
      " |  \n",
      " |  >>> c.view_metadata('sentences')[1]['sent_label']\n",
      " |  'Vidi'\n",
      " |  \n",
      " |  >>> c = c.apply_stoplist(['saw'])\n",
      " |  >>> c.words\n",
      " |  array(['I', 'came', 'conquered'], \n",
      " |    dtype='|S9')\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Corpus\n",
      " |      BaseCorpus\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __init__(self, corpus, context_types=[], context_data=[], remove_empty=True)\n",
      " |  \n",
      " |  apply_stoplist(self, stoplist=[], freq=0)\n",
      " |      Takes a Corpus object and returns a copy of it with words in the\n",
      " |      stoplist removed and with words of frequency <= `freq` removed.\n",
      " |      \n",
      " |      :param stoplist: The list of words to be removed.\n",
      " |      :type stoplist: list\n",
      " |      \n",
      " |      :param freq: A threshold where words of frequency <= 'freq' are\n",
      " |          removed. Default is 0.\n",
      " |      :type freq: integer, optional\n",
      " |          \n",
      " |      :returns: Copy of corpus with words in the stoplist and words\n",
      " |          of frequnecy <= 'freq' removed.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`\n",
      " |  \n",
      " |  in_place_stoplist(self, stoplist=None, freq=0)\n",
      " |      Changes a Corpus object with words in the stoplist removed and with \n",
      " |      words of frequency <= `freq` removed.\n",
      " |      \n",
      " |      :param stoplist: The list of words to be removed.\n",
      " |      :type stoplist: list\n",
      " |      \n",
      " |      :param freq: A threshold where words of frequency <= 'freq' are\n",
      " |          removed. Default is 0.\n",
      " |      :type freq: integer, optional\n",
      " |          \n",
      " |      :returns: Copy of corpus with words in the stoplist and words\n",
      " |          of frequnecy <= 'freq' removed.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`\n",
      " |  \n",
      " |  save = wrapper(*args, **kwargs)\n",
      " |  \n",
      " |  tolist(self, context_type, as_strings=False)\n",
      " |      Returns Corpus object as a list of lists of either integers or\n",
      " |      strings, according to `as_strings`.\n",
      " |      \n",
      " |      :param context_type: The type of tokenization.\n",
      " |      :type context_type: string\n",
      " |      \n",
      " |      :param as_strings: If True, string representations of words are returned.\n",
      " |          Otherwise, integer representations are returned. Default\n",
      " |          is `False`.\n",
      " |      :type as_strings: Boolean, optional\n",
      " |      \n",
      " |      :returns: List of lists\n",
      " |  \n",
      " |  view_contexts(self, ctx_type, as_strings=False, as_slices=False, as_indices=False)\n",
      " |      Displays a tokenization of the corpus.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param as_strings: If True, string representations of words are returned.\n",
      " |          Otherwise, integer representations are returned. Default\n",
      " |          is `False`.\n",
      " |      :type as_strings: Boolean, optional\n",
      " |      \n",
      " |      :param as_slices: If True, a list of slices corresponding to 'ctx_type'\n",
      " |          is returned. Otherwise, integer representations are returned.\n",
      " |          Default is `False`.\n",
      " |      :type as_slices: Boolean, optional\n",
      " |      \n",
      " |      :returns: A tokenized view of `corpus`.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`, :class:`BaseCorpus`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  load(file=None, corpus_dir=None, corpus_file='corpus.npy', words_file='words.npy', metadata_file='metadata.npy')\n",
      " |      Loads data into a Corpus object. \n",
      " |      \n",
      " |      :param file: The file to read. See `numpy.load` for further\n",
      " |          details. Assumes file has been constructed as by\n",
      " |          `Corpus.save`. This option is exclusive of `corpus_dir`.\n",
      " |      :type file: str-like or file object\n",
      " |      \n",
      " |      :param corpus_dir: A directory containing the files\n",
      " |      `corpus_file`, `words_file`, `metadata_file`, from which to\n",
      " |      instantiate a Corpus object. This option is ignored if `file`\n",
      " |      is not `None`.\n",
      " |      :type corpus_dir: string\n",
      " |      \n",
      " |      :param corpus_file: File under `corpus_dir` containing the\n",
      " |      corpus data, stored as a numpy array of integers in an `npy`\n",
      " |      file.\n",
      " |      :type corpus_file: string or file object\n",
      " |      \n",
      " |      :param words_file: File under `corpus_dir` containing the\n",
      " |      corpus vocabulary, stored as a numpy array of strings in an\n",
      " |      `npy` file.  \n",
      " |      :type words_file: string or file object\n",
      " |      \n",
      " |      :param metadata_file: File under `corpus_dir` containing the\n",
      " |      corpus metadata, stored as a numpy stuctured array in an `npy`\n",
      " |      file. Note that this structured array should contain a file\n",
      " |      `idx` which stores the integer indices marking the document\n",
      " |      boundaries.\n",
      " |      :type corpus_file: string or file object\n",
      " |      \n",
      " |      :returns: A Corpus object.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`, :meth:`Corpus.save`, :meth:`numpy.load`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  context_data\n",
      " |  \n",
      " |  context_types\n",
      " |  \n",
      " |  corpus\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  stopped_words\n",
      " |  \n",
      " |  words\n",
      " |  \n",
      " |  words_int\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCorpus:\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of tokens in the corpus.\n",
      " |      \n",
      " |      :See Also: `len(self.words)` for the number of unique tokens.\n",
      " |  \n",
      " |  get_metadatum(self, ctx_type, query, field)\n",
      " |      Returns the metadatum corresponding to the query and the field.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param query: Dictionary with a key, value being a field, label\n",
      " |          in metadata.\n",
      " |      :type query: dictionary-like\n",
      " |      \n",
      " |      :param field: Field of the metadata\n",
      " |      :type field: string\n",
      " |      \n",
      " |      :returns: The metadatum corresponding to the query and the field.\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  meta_int(self, ctx_type, query)\n",
      " |      Returns the index of the metadata found in the query.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param query: Dictionary with a key, value being a field, label\n",
      " |          in metadata.\n",
      " |      :type query: dictionary-like\n",
      " |      \n",
      " |      :returns: The index of the metadata found in the query.\n",
      " |      \n",
      " |      :raises: KeyError\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  remove_empty(self)\n",
      " |      Removes empty tokenizations, if `Corpus` object is not empty.\n",
      " |  \n",
      " |  view_metadata(self, ctx_type)\n",
      " |      Displays the metadata corresponding to a tokenization of the\n",
      " |      corpus. This method can be used in :class:`Corpus` as well as\n",
      " |      :class:`BaseCorpus`\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :returns: The metadata for a tokenization.\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`, :class:`Corpus`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get help on particular methods. For example, there are many arguments to `v.topics()` beyond `print_len`. These can be seen by calling `help(v.topics)` without parentheses after `v.topics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method topics in module vsm.viewer.ldacgsviewer:\n",
      "\n",
      "topics(self, topic_indices=None, sort=None, print_len=10, as_strings=True, compact_view=True, topic_labels=None) method of vsm.viewer.ldacgsviewer.LdaCgsViewer instance\n",
      "    Returns a list of topics estimated by the model. \n",
      "    Each topic is represented by a list of words and the corresponding \n",
      "    probabilities.\n",
      "    \n",
      "    :param topic_indices: List of indices of topics to be\n",
      "        displayed. Default is all topics.\n",
      "    :type topic_indices: list of integers\n",
      "    \n",
      "    :param sort: Topic sort function.\n",
      "    :type sort: string, values are \"entropy\", \"oscillation\", \"index\", \"jsd\",\n",
      "        \"user\" (default if topic_indices set), \"index\" (default)\n",
      "    \n",
      "    :param print_len: Number of words shown for each topic. Default is 10.\n",
      "    :type print_len: int, optional\n",
      "    \n",
      "    :param as_string: If `True`, each topic displays words rather than its\n",
      "        integer representation. Default is `True`.\n",
      "    :type as_string: boolean, optional\n",
      "    \n",
      "    :param compact_view: If `True`, topics are simply represented as\n",
      "        their top `print_len` number of words. Otherwise, topics are\n",
      "        shown as words and their probabilities. Default is `True`.\n",
      "    :type compact_view: boolean, optional       \n",
      "    \n",
      "    :param topic_labels: List of strings that are names that correspond\n",
      "        to the topics in `topic_indices`.\n",
      "    :type topic_labels: list, optional\n",
      "    \n",
      "    :returns: an instance of :class:`DataTable`.\n",
      "        A structured array of topics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(v.topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `help(v.topics())` *with* parentheses will return help for the object reutrned by `v.topics()`, which is a `DataTable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataTable in module vsm.viewer.labeleddata object:\n",
      "\n",
      "class DataTable(__builtin__.list)\n",
      " |  A subclass of list whose purpose is to store labels and\n",
      " |  formatting information for a list of 1-dimensional structured\n",
      " |  arrays. It also provides pretty-printing routines.\n",
      " |  \n",
      " |  Globally, the table has a default display length for the columns\n",
      " |  and a table header.\n",
      " |  \n",
      " |  A column can have a column-specific header.\n",
      " |  \n",
      " |  A subcolumn wraps the data found under a given field name. Each\n",
      " |  subcolumn has a label and a display width.\n",
      " |  \n",
      " |  :param l: List of 1-dimensional structured arrays.\n",
      " |  :type l: list\n",
      " |  \n",
      " |  :param table_header: The title of the object. Default is `None`.\n",
      " |  :type table_header: string, optional\n",
      " |  \n",
      " |  :param compact_view: If `True` the DataTable is displayed with its\n",
      " |      tokens only without the probabilities. Default is `True`\n",
      " |  :type compact_view: boolean, optional\n",
      " |  \n",
      " |  :attributes:\n",
      " |      * **table_header** (string)\n",
      " |          The title of the object. Default is `None`.\n",
      " |      * **compact_view** (boolean)\n",
      " |          Option of viewing tokens with or without the probabilities.\n",
      " |  :methods:\n",
      " |      * **__str__**\n",
      " |          Returns a pretty printed string version of the object.\n",
      " |      * **_repr_html_**\n",
      " |          Returns an html table in ipython online session.\n",
      " |  \n",
      " |  **Examples**\n",
      " |  \n",
      " |  >>>  words = ['there','will','be','an','answer']\n",
      " |  >>>  values = [random.random() for w in words]\n",
      " |  >>>  arr = np.array(zip(words, values), \n",
      " |          dtype=[('i', np.array(words).dtype), \n",
      " |          ('value', np.array(values).dtype)])\n",
      " |  >>>  lc = LabeledColumn(arr, 'Lyrics')\n",
      " |  >>>  l = [lc.copy() for i in xrange(2)]\n",
      " |  >>>  dt = DataTable(l, 'Let it be', subcolhdr_compact=['Topic', 'Words'],\n",
      " |                 subcolhdr_full=['Word', 'Prob'], compact_view=True)\n",
      " |  >>>  print dt\n",
      " |  --------------------------------------------\n",
      " |                   Let it be                  \n",
      " |  --------------------------------------------\n",
      " |  Topic      Words      \n",
      " |  --------------------------------------------\n",
      " |  Lyrics     there      will       be         \n",
      " |             an         answer     \n",
      " |  --------------------------------------------\n",
      " |  Lyrics     there      will       be         \n",
      " |             an         answer     \n",
      " |  --------------------------------------------\n",
      " |  \n",
      " |  >>> dt.compact_view = False\n",
      " |  >>>  print dt\n",
      " |      Let it be      \n",
      " |  ---------------------\n",
      " |          Words        \n",
      " |  ---------------------\n",
      " |  Word       Value     \n",
      " |  ---------------------\n",
      " |  there      0.58793   \n",
      " |  will       0.29624   \n",
      " |  be         0.00209   \n",
      " |  an         0.27221   \n",
      " |  answer     0.96118   \n",
      " |  ---------------------\n",
      " |          Words        \n",
      " |  ---------------------\n",
      " |  Word       Value     \n",
      " |  ---------------------\n",
      " |  there      0.22608   \n",
      " |  will       0.64567   \n",
      " |  be         0.02832   \n",
      " |  an         0.31118   \n",
      " |  answer     0.23083\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataTable\n",
      " |      __builtin__.list\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getslice__(self, i, j)\n",
      " |  \n",
      " |  __init__(self, l, table_header=None, compact_view=True, subcolhdr_compact=None, subcolhdr_full=None)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Pretty prints the DataTable when `print` method is used.\n",
      " |  \n",
      " |  __str_compact__(self, subcol_headers)\n",
      " |      Prints DataTable when `compact_view` is `True`.\n",
      " |  \n",
      " |  __str_full__(self, subcol_headers)\n",
      " |      Prints DataTable when `compact_view` is `False`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from __builtin__.list:\n",
      " |  \n",
      " |  __add__(...)\n",
      " |      x.__add__(y) <==> x+y\n",
      " |  \n",
      " |  __contains__(...)\n",
      " |      x.__contains__(y) <==> y in x\n",
      " |  \n",
      " |  __delitem__(...)\n",
      " |      x.__delitem__(y) <==> del x[y]\n",
      " |  \n",
      " |  __delslice__(...)\n",
      " |      x.__delslice__(i, j) <==> del x[i:j]\n",
      " |      \n",
      " |      Use of negative indices is not supported.\n",
      " |  \n",
      " |  __eq__(...)\n",
      " |      x.__eq__(y) <==> x==y\n",
      " |  \n",
      " |  __ge__(...)\n",
      " |      x.__ge__(y) <==> x>=y\n",
      " |  \n",
      " |  __getattribute__(...)\n",
      " |      x.__getattribute__('name') <==> x.name\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(...)\n",
      " |      x.__gt__(y) <==> x>y\n",
      " |  \n",
      " |  __iadd__(...)\n",
      " |      x.__iadd__(y) <==> x+=y\n",
      " |  \n",
      " |  __imul__(...)\n",
      " |      x.__imul__(y) <==> x*=y\n",
      " |  \n",
      " |  __iter__(...)\n",
      " |      x.__iter__() <==> iter(x)\n",
      " |  \n",
      " |  __le__(...)\n",
      " |      x.__le__(y) <==> x<=y\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      x.__len__() <==> len(x)\n",
      " |  \n",
      " |  __lt__(...)\n",
      " |      x.__lt__(y) <==> x<y\n",
      " |  \n",
      " |  __mul__(...)\n",
      " |      x.__mul__(n) <==> x*n\n",
      " |  \n",
      " |  __ne__(...)\n",
      " |      x.__ne__(y) <==> x!=y\n",
      " |  \n",
      " |  __repr__(...)\n",
      " |      x.__repr__() <==> repr(x)\n",
      " |  \n",
      " |  __reversed__(...)\n",
      " |      L.__reversed__() -- return a reverse iterator over the list\n",
      " |  \n",
      " |  __rmul__(...)\n",
      " |      x.__rmul__(n) <==> n*x\n",
      " |  \n",
      " |  __setitem__(...)\n",
      " |      x.__setitem__(i, y) <==> x[i]=y\n",
      " |  \n",
      " |  __setslice__(...)\n",
      " |      x.__setslice__(i, j, y) <==> x[i:j]=y\n",
      " |      \n",
      " |      Use  of negative indices is not supported.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      L.__sizeof__() -- size of L in memory, in bytes\n",
      " |  \n",
      " |  append(...)\n",
      " |      L.append(object) -- append object to end\n",
      " |  \n",
      " |  count(...)\n",
      " |      L.count(value) -> integer -- return number of occurrences of value\n",
      " |  \n",
      " |  extend(...)\n",
      " |      L.extend(iterable) -- extend list by appending elements from the iterable\n",
      " |  \n",
      " |  index(...)\n",
      " |      L.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  insert(...)\n",
      " |      L.insert(index, object) -- insert object before index\n",
      " |  \n",
      " |  pop(...)\n",
      " |      L.pop([index]) -> item -- remove and return item at index (default last).\n",
      " |      Raises IndexError if list is empty or index is out of range.\n",
      " |  \n",
      " |  remove(...)\n",
      " |      L.remove(value) -- remove first occurrence of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  reverse(...)\n",
      " |      L.reverse() -- reverse *IN PLACE*\n",
      " |  \n",
      " |  sort(...)\n",
      " |      L.sort(cmp=None, key=None, reverse=False) -- stable sort *IN PLACE*;\n",
      " |      cmp(x, y) -> -1, 0, 1\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from __builtin__.list:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __new__ = <built-in method __new__ of type object>\n",
      " |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(v.topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to emphasize that this functionality can be used with any python library, including the standard library. For example, one could look at all the functions included in the `math` library by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function log in module math:\n",
      "\n",
      "log(...)\n",
      "    log(x[, base])\n",
      "    \n",
      "    Return the logarithm of x to the given base.\n",
      "    If the base not specified, returns the natural logarithm (base e) of x.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "help(math.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Examples\n",
    "\n",
    "This notebook gives some basic building blocks for using the Topic Explorer. Additional examples can be found on GitHub in the [inpho/vsm-demo-notebooks repository](http://github.com/inpho/vsm-demo-notebooks).\n",
    "\n",
    "# Contact Information\n",
    "If you have additional questions regarding the InPhO Topic Explorer or have comments on this tutorial, please e-mail [tutorial@hypershelf.org](mailto:tutorial@hypershelf.org).\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
