{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "How similar are the topics that we get from our models to the topics that Slingerland & Nichols found      \n",
    "Did we find the same or similar topics?    \n",
    "compare the highet probability words in their model to th e highest probability words in our models    \n",
    "use rank correlation such as Spearman's rho    \n",
    "链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from notebook, using serial load function.\n",
      "[20, 40, 60, 80, 100]\n",
      "/home/lab/InPhO_project/inpho/kmx/models/kmx-freq5-freq5-N2523342-LDA-K{0}-document-1000.npz\n",
      "load the model with topic 100\n",
      "Loading LDA data from /home/lab/InPhO_project/inpho/kmx/models/kmx-freq5-freq5-N2523342-LDA-K100-document-1000.npz\n"
     ]
    }
   ],
   "source": [
    "from corpus import *\n",
    "from vsm import *\n",
    "\n",
    "k = topic_range[4]\n",
    "print \"load the model with topic \" + str(k)\n",
    "v = lda_v[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function\n",
    "def printlist(example):\n",
    "    case_list_righ = str(example).replace('u\\'','\\'')\n",
    "    print case_list_righ.decode(\"unicode-escape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['天', '上', '下', '大', '道', '中', '人', '时', '后', '地', '长', '从', '成', '德'], ['心', '见', '明', '合', '失', '平', '阳', '意', '神', '福', '离', '阴', '各', '惑'], ['君', '人', '公', '能', '死', '见', '欲', '知', '先', '得', '父', '臣', '事', '辞'], ['民', '君', '行', '国', '治', '能', '得', '事', '政', '下', '食', '教', '官', '道'], ['天', '道', '下', '物', '知', '德', '生', '能', '圣', '人', '得', '身', '言', '神'], ['国', '日', '食', '归', '成', '乐', '白', '东', '亡', '师', '走', '害', '望', '夜'], ['人', '得', '相', '发', '士', '小', '时', '杀', '用', '意', '石', '立', '莫', '主'], ['君', '人', '义', '礼', '能', '贤', '莫', '天', '恶', '安', '乱', '下', '善', '性'], ['人', '知', '言', '名', '用', '治', '能', '欲', '学', '文', '小', '富', '彼', '盗'], ['今', '心', '后', '力', '忧', '岂', '朝', '死', '诚', '弃', '观', '入', '罪', '古']]\n"
     ]
    }
   ],
   "source": [
    "# top 10 topics in Slingerland & Nichols paper\n",
    "from hanziconv import HanziConv\n",
    "top29 = '天 上 下 大 道 中 人 時 後 地 長 從 成 德'\n",
    "top97 = '心 見 明 合 失 平 陽 意 神 福 離 陰 各 惑'\n",
    "top76 = '君 人 公 能 死 見 欲 知 先 得 父 臣 事 辭'\n",
    "top21 = '民 君 行 國 治 能 得 事 政 下 食 教 官 道'\n",
    "top23 = '天 道 下 物 知 德 生 能 聖 人 得 身 言 神'\n",
    "top66 = '國 日 食 歸 成 樂 白 東 亡 師 走 害 望 夜'\n",
    "top72 = '人 得 相 發 士 小 時 殺 用 意 石 立 莫 主'\n",
    "top34 = '君 人 義 禮 能 賢 莫 天 惡 安 亂 下 善 性'\n",
    "top78 = '人 知 言 名 用 治 能 欲 學 文 小 富 彼 盜'\n",
    "top10 = '今 心 後 力 憂 豈 朝 死 誠 棄 觀 入 罪 古'\n",
    "top10_traditional = [top29,top97,top76,top21,top23,top66,top72,top34,top78,top10]\n",
    "\n",
    "top10_simplified = []\n",
    "for topic in top10_traditional:\n",
    "    topic_simplified = HanziConv.toSimplified(topic)\n",
    "    topic_simplified = topic_simplified.split(' ')\n",
    "    top10_simplified.append(topic_simplified)\n",
    "printlist(top10_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a funciton to caculate the similarity between topics using spearman's rho\n",
    "def topic_alignment(topic_words_nichols):\n",
    "    max_related = []\n",
    "    topic_dict = {}\n",
    "    topic_number = 0\n",
    "    for words_probility_list in v.topics():\n",
    "        temp = []\n",
    "        for word in topic_words_nichols:\n",
    "            count = 0\n",
    "            for word_probility in words_probility_list:\n",
    "                if word.decode('utf-8') == word_probility[0].decode('utf-8'):\n",
    "                    temp.append(count)\n",
    "                    break\n",
    "                else:\n",
    "                    count += 1\n",
    "            if count == len(words_probility_list):\n",
    "                temp.append(-1)\n",
    "        topic_dict[topic_number] = temp\n",
    "        topic_number += 1\n",
    "        \n",
    "    max_num, p_value = spearmanr(range(0,len(topic_words_nichols)),topic_dict[0])\n",
    "    for key in topic_dict:\n",
    "        rho, p_value = spearmanr(range(0,len(topic_words_nichols)),topic_dict[key])\n",
    "        if max_num < rho:\n",
    "            max_related = []\n",
    "            max_related.append(key)\n",
    "            max_num = rho\n",
    "        elif max_num == rho:\n",
    "            max_related.append(key)\n",
    "    print 'the most related topic or topics are'\n",
    "    print set(max_related)\n",
    "    return set(max_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[6]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[7]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[8]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_alignment(top10_simplified[9]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
