{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Explorer Notebook Tutorial\n",
    "\n",
    "The InPhO Topic Explorer features a powerful interactive coding environment that enables direct manipulation of the corpus and models, in contrast to the web visualization.\n",
    "\n",
    "When you run the `vsm notebook` command, several things happen:\n",
    "1.  The Topic Explorer creates a new folder called `notebooks` and places several files inside it:\n",
    "     -  **corpus.py** contains Python code which imports the Corpus object and a function that will load models trained on your corpus. It gathers this information from your `CORPUS.ini` file, where `CORPUS` is the name of the folder you prepared. More information on this special file is below.\n",
    "     -  **Topic Explorer Tutorial.ipynb** is this file, which provides the skeleton documentation for interacting with the models.\n",
    "     -  Other **ipynb** files, containing analyses that can be re-run on your own corpora.\n",
    "2.  The Topic Explorer launches a [Jupyter Notebook](http://jupyter.org/). This allows you to program in Python on your local computer using the browser, rather than a terminal or other program. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Jupyter\n",
    "If you look in the address bar of your browser, it should start with something like `localhost:8888/notebooks/Topic%20Explorer%20Tutorial.ipynb`. If you open a new tab or browser window and type in `localhost:8888` you will open the same list of files and be able to edit multiple files at once. Note that editing the same file in multiple tabs may cause you to accidentally overwrite your data. Jupyter does not check if the file is already open.\n",
    "\n",
    "Also, note that if the first portion of the url (`localhost:8888`) is different, you will need to enter what it says on your computer to open a new tab. Most likely the \"port number\" (`8888`) will be different, and may indicate you have a second instance of `vsm notebook` or another Jupyter Notebook server running.\n",
    "\n",
    "\n",
    "### Running Cells\n",
    "The Jupyter notebook operates through individual *cells* that run Python code. To run a cell press the \"run cell\" (play) button or select the cell by clicking on it, then select in the Jupyter menu \"Cell > Run Cells\".\n",
    "\n",
    "Try running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Hello world!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately below the cell, the `Hello world!` should be printed, and to the left of the cell it should say `In [1]:`.\n",
    "\n",
    "#### A note on kernels and brackets\n",
    "If the number `[1]` is different, nothing is wrong, so long as there is a number printed.\n",
    "\n",
    "The number in brackets (`[1]`) counts the number of times you have run a cell in this notebook session. A notebook session is tied to a *kernel*. The kernel runs the Python code. If you wish to reset the numbers and run your code step-by-step, starting from `[1]` again, go to the menu and select \"Kernel > Restart & Run All\".\n",
    "\n",
    "If the number appears as `In [*]:` that means that the cell is currently running. When it changes to a number (`[2]`), then the files have completed importing.\n",
    "\n",
    "If you feel this is taking an absurdly long time to load (in excess of a few seconds), please press the stop button and notify the package developers. There might be a bug in the modeling software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors and Debugging\n",
    "Each cell automatically calls `print` on the last line of the cell. Run the cell below to see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this to print `Hello world!` once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hello world!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D'oh!** This should have raised a `SyntaxError: invalid syntax`.\n",
    "\n",
    "Note the message `File \"<ipython-input-5-59ca0efa9f56>\", line 1` (the portion after `ipython-input` may be different). This tells you which line in the program errored. If you have errors in more advanced code, the line number will be very helpful in diagnosing the problem.\n",
    "\n",
    "For now, change the cell above to `\"Hello world!\"` and run again to get the proper output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing `corpus.py`\n",
    "Now that you know how to run a cell, we can begin interacting with the topic models. First we will import your corpus objects. Select and run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from notebook, using serial load function.\n",
      "[20, 40, 60, 80, 100]\n",
      "/home/hongliang/inpho/kmx/models/kmx-freq5-nltk-en-freq5-N1000000-LDA-K{0}-document-2000.npz\n"
     ]
    }
   ],
   "source": [
    "from corpus import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now have access to several variables, the most important of which are:\n",
    " -  `c` -- The `vsm.Corpus` object\n",
    " -  `lda_v` -- A dictionary containing each of the `vsm.LdaViewer` instances. You can access a particular model with `lda_v[k]`, substituting k for a particular number, like `lda_v[20]` for the 20-topic model. If the model for that number of topics has not been trained, it will error.\n",
    " -  `topic_range` -- A list of the trained models (e.g., `[20, 40, 60, 80]`)\n",
    " -  `context_type` -- A string containing the particular context type modeled (e.g., `\"sentence\"`, `\"document\"`, `\"article\"`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the `vsm` module\n",
    "\n",
    "The InPhO Topic Explorer is comprised of two modules:\n",
    "1. The `topicexplorer` module contains code for the visualization and user interfaces.\n",
    "2. The `vsm` module contains code for modeling differnet corpora. \n",
    "\n",
    "In order to make use of the term frequency (TF), term frequency-inverse document frequency (TfIdf), and latent semantic analysis (LSA) models, we must import the main vsm module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vsm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the Corpus: Term Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above has loaded your `Corpus` object into the `c` variable. You can see the list of all words that are in your corpus by typing `c.words` into a code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'10', u'11', u'12', ..., u'\\ue859', u'\\ufe51', u'\\ufe56'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it only shows the first few and last few unique words in the corpus, alphabetically sorted. \n",
    "\n",
    "What if we want to get a list of how often each word occurs? For that, we can use the `vsm.model.TF` to build a frequency distribution over the terms in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan                    =\"4\">Collection Frequencies</th></tr><tr><th style=\"text-align: center; background: #EFF2FB; \">Word                    </th><th style=\"text-align: center; background: #EFF2FB; \">Counts                    </th><th style=\"text-align: center; background: #EFF2FB; \">Word                    </th><th style=\"text-align: center; background: #EFF2FB; \">Counts                    </th></tr><tr><td>　                          </td><td>85353                      </td><td>可                          </td><td>19979                      </td></tr><tr><td>人                          </td><td>58190                      </td><td>年                          </td><td>18621                      </td></tr><tr><td>王                          </td><td>40022                      </td><td>君                          </td><td>18610                      </td></tr><tr><td>天                          </td><td>27953                      </td><td>行                          </td><td>17434                      </td></tr><tr><td>十                          </td><td>27782                      </td><td>侯                          </td><td>17097                      </td></tr><tr><td>一                          </td><td>27692                      </td><td>将                          </td><td>17022                      </td></tr><tr><td>二                          </td><td>24084                      </td><td>使                          </td><td>16665                      </td></tr><tr><td>上                          </td><td>23027                      </td><td>能                          </td><td>16637                      </td></tr><tr><td>国                          </td><td>21488                      </td><td>臣                          </td><td>15908                      </td></tr><tr><td>后                          </td><td>20489                      </td><td>事                          </td><td>15705                      </td></tr></table>"
      ],
      "text/plain": [
       "LabeledColumn([(u'\\u3000', 85353), (u'\\u4eba', 58190), (u'\\u738b', 40022), ...,\n",
       "       (u'\\u7f6d',     6), (u'\\u59e8',     6), (u'\\u5ae0',     6)], \n",
       "      dtype=[('word', '<U14'), ('value', '<i8')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model and create a TfViewer object\n",
    "tf = TF(c, context_type)\n",
    "tf.train()\n",
    "tf_v = TfViewer(c, tf)\n",
    "\n",
    "# print the most frequent terms in the document\n",
    "# remember that IPython automatically prints the last cell of a document\n",
    "tf_v.coll_freqs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell above, you should see a table with the 20 most frequently used words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interacting with Topic Models\n",
    "\n",
    "The InPhO Topic Explorer doesn't just work with term frequencies though - it creates LDA topic models. Through the notebook interface these models can be powerfully manipulated to produce new analyses.\n",
    "\n",
    "First, let's select a primary model to investigate, and load it into the variable `v`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Loading LDA data from /home/hongliang/inpho/kmx/models/kmx-freq5-nltk-en-freq5-N1000000-LDA-K20-document-2000.npz\n"
     ]
    }
   ],
   "source": [
    "# print the number of topics in the first model\n",
    "print topic_range[0]\n",
    "# remember that list indexes start with 0 not 1!\n",
    "\n",
    "# replace 'topic_range[0]' with a specific number, if you like\n",
    "k = topic_range[0]\n",
    "\n",
    "# load the topic model\n",
    "v = lda_v[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code loads the first topic model into a viewer object. We have used the `topic_range[0]` instead of simply stating a number so that this same demo notebook will work with any model settings you've prepared. This portability enables us to write analyses that can be replicated across any corpus, and is one of the real strengths of using the `from corpus import *` model of coding your notebooks. If others are using the Topic Explorer to generate their objects, they can run the exact same analysis on different corpora, so long as the variable names are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `v.topics()`\n",
    "First, lets print a list of topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan            =\"11\">Topics Sorted by Index</th></tr><tr><th style=\"text-align: center; background: #EFF2FB;\"                  >Topic</th><th style=\"text-align: center; background: #EFF2FB;\"                  >Words</th></tr><tr><td style=\"padding-left:0.75em;\">Topic 0</td><td> 王, 秦, 齐, 楚, 魏, 赵, 君, 本, 国, 鲍           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 1</td><td> 　, 一, 二, 次, 测, 十, 本, 正, 初, 时           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 2</td><td> 人, 天, 能, 生, 道, 物, 圣, 可, 神, 地           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 3</td><td> 气, 阳, 病, 阴, 脉, 上, 少, 帝, 寒, 热           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 4</td><td> 人, 民, 令, 国, 二, 事, 十, 士, 食, 官           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 5</td><td> 十, 一, 二, 百, 分, 千, 尺, 法, 万, 日           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 6</td><td> 心, 山, 风, 车, 可, 日, 方, 衣, 水, 木           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 7</td><td> 太, 后, 帝, 年, 上, 人, 书, 时, 及, 郡           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 8</td><td> 月, 日, 天, 年, 十, 星, 二, 阳, 行, 岁           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 9</td><td> 王, 侯, 人, 上, 后, 太, 将, 军, 汉, 使           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 10</td><td> 文, 本, 书, 字, 一, 传, 说, 二, 义, 篇           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 11</td><td> 人, 民, 天, 可, 国, 能, 道, 上, 行, 治           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 12</td><td> 山, 十, 东, 水, 百, 南, 里, 西, 多, 国           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 13</td><td> 人, 君, 可, 行, 闻, 孔, 臣, 死, 能, 使           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 14</td><td> 汤, 一, 升, 二, 服, 脉, 方, 寒, 病, 水           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 15</td><td> 晋, 人, 侯, 年, 齐, 月, 十, 郑, 楚, 君           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 16</td><td> 王, 天, 礼, 德, 周, 乐, 民, 命, 后, 帝           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 17</td><td> 利, 人, 象, 福, 行, 上, 失, 吉, 家, 明           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 18</td><td> 将, 军, 兵, 人, 汉, 王, 使, 奴, 匈, 击           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 19</td><td> 人, 主, 拜, 宾, 西, 爵, 上, 祭, 东, 升           </td></tr></table>"
      ],
      "text/plain": [
       "[LabeledColumn([(u'\\u738b',   5.37732467e-02), (u'\\u79e6',   3.23017091e-02),\n",
       "        (u'\\u9f50',   1.76518895e-02), ..., (u'\\u8881',   5.70625254e-08),\n",
       "        (u'\\u8fdd',   5.70625254e-08), (u'\\u3000',   5.58410065e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u3000',   7.08128333e-01), (u'\\u4e00',   4.88491245e-02),\n",
       "        (u'\\u4e8c',   2.92297006e-02), ..., (u'\\u5e74',   8.11847229e-08),\n",
       "        (u'\\u4faf',   8.11847229e-08), (u'\\u4eba',   8.11847229e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   4.15202342e-02), (u'\\u5929',   2.54693162e-02),\n",
       "        (u'\\u80fd',   1.82827543e-02), ..., (u'\\u5426',   3.92407600e-08),\n",
       "        (u'\\u9a87',   3.92107822e-08), (u'\\u3000',   3.83714074e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6c14',   3.64489071e-02), (u'\\u9633',   2.44362261e-02),\n",
       "        (u'\\u75c5',   2.03468017e-02), ..., (u'\\u9519',   9.11968243e-08),\n",
       "        (u'\\u5bdd',   9.11620077e-08), (u'\\u3000',   8.91423753e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   3.52982394e-02), (u'\\u6c11',   2.20381208e-02),\n",
       "        (u'\\u4ee4',   1.74067765e-02), ..., (u'\\u89c4',   7.44809796e-08),\n",
       "        (u'\\u4fed',   7.44240793e-08), (u'\\u6e90',   7.44240793e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5341',   1.18593730e-01), (u'\\u4e00',   8.46386403e-02),\n",
       "        (u'\\u4e8c',   6.35023788e-02), ..., (u'\\u5e90',   1.55493453e-07),\n",
       "        (u'\\u987e',   1.55434037e-07), (u'\\u3000',   1.52106693e-07)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5fc3',   5.60969580e-03), (u'\\u5c71',   5.56980586e-03),\n",
       "        (u'\\u98ce',   4.89166193e-03), ..., (u'\\u987a',   4.97600503e-08),\n",
       "        (u'\\u592a',   4.96078769e-08), (u'\\u3000',   4.86948508e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u592a',   1.16873449e-02), (u'\\u540e',   1.09254830e-02),\n",
       "        (u'\\u5e1d',   1.06620723e-02), ..., (u'\\u94c1',   2.02512265e-08),\n",
       "        (u'\\u5026',   2.02434975e-08), (u'\\u500d',   2.02357668e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6708',   5.76299019e-02), (u'\\u65e5',   2.56369933e-02),\n",
       "        (u'\\u5929',   2.32239217e-02), ..., (u'\\u75db',   7.86949030e-08),\n",
       "        (u'\\u59ec',   7.86347343e-08), (u'\\u3000',   7.70102986e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u738b',   3.93675603e-02), (u'\\u4faf',   1.52511653e-02),\n",
       "        (u'\\u4eba',   1.43742710e-02), ..., (u'\\u8c08',   3.43167663e-08),\n",
       "        (u'\\u6cc9',   3.43167663e-08), (u'\\u8a89',   3.43167663e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6587',   2.41017547e-02), (u'\\u672c',   2.35150568e-02),\n",
       "        (u'\\u4e66',   2.31483728e-02), ..., (u'\\u60a3',   5.23548422e-08),\n",
       "        (u'\\u62c2',   5.23348618e-08), (u'\\u51a5',   5.23148778e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   2.10216213e-02), (u'\\u6c11',   1.80866010e-02),\n",
       "        (u'\\u5929',   1.61350146e-02), ..., (u'\\u7678',   2.54539252e-08),\n",
       "        (u'\\u5934',   2.54442067e-08), (u'\\u56f4',   2.53858925e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5c71',   3.43977399e-02), (u'\\u5341',   2.55139004e-02),\n",
       "        (u'\\u4e1c',   2.46226713e-02), ..., (u'\\u76c8',   9.46871950e-08),\n",
       "        (u'\\u653f',   9.46148617e-08), (u'\\u79bd',   9.46148617e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   2.96049751e-02), (u'\\u541b',   2.03464124e-02),\n",
       "        (u'\\u53ef',   1.33574223e-02), ..., (u'\\u97e9',   2.95355225e-08),\n",
       "        (u'\\u6545\\u4e8b',   2.95129752e-08), (u'\\u57ce',   2.94904297e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6c64',   2.68273242e-02), (u'\\u4e00',   2.07225215e-02),\n",
       "        (u'\\u5347',   2.03090478e-02), ..., (u'\\u5510',   2.42621724e-07),\n",
       "        (u'\\u795e',   2.42343361e-07), (u'\\u3000',   2.37518762e-07)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u664b',   2.26491448e-02), (u'\\u4eba',   2.17277929e-02),\n",
       "        (u'\\u4faf',   2.08111908e-02), ..., (u'\\u7eaf',   4.74119020e-08),\n",
       "        (u'\\u90e8',   4.74119020e-08), (u'\\u529d',   4.73937867e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u738b',   2.82079987e-02), (u'\\u5929',   2.42411792e-02),\n",
       "        (u'\\u793c',   1.43716484e-02), ..., (u'\\u6ce2',   4.99573254e-08),\n",
       "        (u'\\u6e20',   4.99191586e-08), (u'\\u9634',   4.96138455e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5229',   1.03856046e-02), (u'\\u4eba',   8.76106322e-03),\n",
       "        (u'\\u8c61',   8.29690881e-03), ..., (u'\\u730e',   1.44857964e-07),\n",
       "        (u'\\u6885',   1.44857964e-07), (u'\\u90c1',   1.44747304e-07)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5c06',   2.71455962e-02), (u'\\u519b',   2.22872980e-02),\n",
       "        (u'\\u5175',   1.85539275e-02), ..., (u'\\u64c5',   4.90775989e-08),\n",
       "        (u'\\u8fa9',   4.90588583e-08), (u'\\u7978',   4.90588583e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   3.05130333e-02), (u'\\u4e3b',   2.41580866e-02),\n",
       "        (u'\\u62dc',   2.31242664e-02), ..., (u'\\u4e60',   1.51774813e-07),\n",
       "        (u'\\u667a',   1.51716819e-07), (u'\\u6559',   1.51716819e-07)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the number of words printed per topic, use the `print_len` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan            =\"21\">Topics Sorted by Index</th></tr><tr><th style=\"text-align: center; background: #EFF2FB;\"                  >Topic</th><th style=\"text-align: center; background: #EFF2FB;\"                  >Words</th></tr><tr><td style=\"padding-left:0.75em;\">Topic 0</td><td> 王, 秦, 齐, 楚, 魏, 赵, 君, 本, 国, 鲍, 吴, 臣, 一, 人, 兵, 年, 韩, 使, 攻, 二           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 1</td><td> 　, 一, 二, 次, 测, 十, 本, 正, 初, 时, 和, 阳, 小, 食, 太, 母, ─, 聚, 案, 父           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 2</td><td> 人, 天, 能, 生, 道, 物, 圣, 可, 神, 地, 时, 气, 死, 德, 行, 形, 一, 性, 善, 世           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 3</td><td> 气, 阳, 病, 阴, 脉, 上, 少, 帝, 寒, 热, 伯, 人, 刺, 岐, 血, 足, 痛, 治, 心, 出           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 4</td><td> 人, 民, 令, 国, 二, 事, 十, 士, 食, 官, 百, 一, 田, 掌, 物, 王, 上, 祭, 祀, 岁           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 5</td><td> 十, 一, 二, 百, 分, 千, 尺, 法, 万, 日, 乘, 寸, 步, 数, 度, 人, 上, 术, 实, 余           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 6</td><td> 心, 山, 风, 车, 可, 日, 方, 衣, 水, 木, 白, 流, 南, 马, 离, 游, 玉, 高, 生, 人           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 7</td><td> 太, 后, 帝, 年, 上, 人, 书, 时, 及, 郡, 臣, 事, 令, 诏, 吏, 光, 复, 侯, 司, 官           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 8</td><td> 月, 日, 天, 年, 十, 星, 二, 阳, 行, 岁, 阴, 正, 冬, 太, 夏, 地, 水, 气, 元, 始           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 9</td><td> 王, 侯, 人, 上, 后, 太, 将, 军, 汉, 使, 臣, 帝, 立, 兵, 天, 阳, 高, 年, 十, 赵           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 10</td><td> 文, 本, 书, 字, 一, 传, 说, 二, 义, 篇, 汉, 按, 十, 引, 卷, 记, 后, 世, 正, 史           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 11</td><td> 人, 民, 天, 可, 国, 能, 道, 上, 行, 治, 事, 臣, 君, 法, 主, 利, 明, 义, 乱, 贤           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 12</td><td> 山, 十, 东, 水, 百, 南, 里, 西, 多, 国, 北, 阳, 莽, 上, 帝, 出, 千, 河, 二, 海           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 13</td><td> 人, 君, 可, 行, 闻, 孔, 臣, 死, 能, 使, 国, 对, 王, 父, 君子, 将, 礼, 士, 晏, 道           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 14</td><td> 汤, 一, 升, 二, 服, 脉, 方, 寒, 病, 水, 汗, 温, 味, 热, 去, 发, 黄, 甘, 主, 日           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 15</td><td> 晋, 人, 侯, 年, 齐, 月, 十, 郑, 楚, 君, 师, 伯, 伐, 王, 使, 宋, 卫, 叔, 卒, 氏           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 16</td><td> 王, 天, 礼, 德, 周, 乐, 民, 命, 后, 帝, 明, 成, 文, 武, 侯, 诗, 宗, 敬, 时, 祭           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 17</td><td> 利, 人, 象, 福, 行, 上, 失, 吉, 家, 明, 忧, 小, 过, 国, 复, 安, 德, 咎, 凶, 归           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 18</td><td> 将, 军, 兵, 人, 汉, 王, 使, 奴, 匈, 击, 单, 国, 城, 西, 万, 千, 遣, 骑, 马, 破           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 19</td><td> 人, 主, 拜, 宾, 西, 爵, 上, 祭, 东, 升, 坐, 执, 阶, 受, 面, 降, 南, 礼, 尸, 丧           </td></tr></table>"
      ],
      "text/plain": [
       "[LabeledColumn([(u'\\u738b',   5.37732467e-02), (u'\\u79e6',   3.23017091e-02),\n",
       "        (u'\\u9f50',   1.76518895e-02), ..., (u'\\u8881',   5.70625254e-08),\n",
       "        (u'\\u8fdd',   5.70625254e-08), (u'\\u3000',   5.58410065e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u3000',   7.08128333e-01), (u'\\u4e00',   4.88491245e-02),\n",
       "        (u'\\u4e8c',   2.92297006e-02), ..., (u'\\u5e74',   8.11847229e-08),\n",
       "        (u'\\u4faf',   8.11847229e-08), (u'\\u4eba',   8.11847229e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   4.15202342e-02), (u'\\u5929',   2.54693162e-02),\n",
       "        (u'\\u80fd',   1.82827543e-02), ..., (u'\\u5426',   3.92407600e-08),\n",
       "        (u'\\u9a87',   3.92107822e-08), (u'\\u3000',   3.83714074e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6c14',   3.64489071e-02), (u'\\u9633',   2.44362261e-02),\n",
       "        (u'\\u75c5',   2.03468017e-02), ..., (u'\\u9519',   9.11968243e-08),\n",
       "        (u'\\u5bdd',   9.11620077e-08), (u'\\u3000',   8.91423753e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   3.52982394e-02), (u'\\u6c11',   2.20381208e-02),\n",
       "        (u'\\u4ee4',   1.74067765e-02), ..., (u'\\u89c4',   7.44809796e-08),\n",
       "        (u'\\u4fed',   7.44240793e-08), (u'\\u6e90',   7.44240793e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5341',   1.18593730e-01), (u'\\u4e00',   8.46386403e-02),\n",
       "        (u'\\u4e8c',   6.35023788e-02), ..., (u'\\u5e90',   1.55493453e-07),\n",
       "        (u'\\u987e',   1.55434037e-07), (u'\\u3000',   1.52106693e-07)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5fc3',   5.60969580e-03), (u'\\u5c71',   5.56980586e-03),\n",
       "        (u'\\u98ce',   4.89166193e-03), ..., (u'\\u987a',   4.97600503e-08),\n",
       "        (u'\\u592a',   4.96078769e-08), (u'\\u3000',   4.86948508e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u592a',   1.16873449e-02), (u'\\u540e',   1.09254830e-02),\n",
       "        (u'\\u5e1d',   1.06620723e-02), ..., (u'\\u94c1',   2.02512265e-08),\n",
       "        (u'\\u5026',   2.02434975e-08), (u'\\u500d',   2.02357668e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6708',   5.76299019e-02), (u'\\u65e5',   2.56369933e-02),\n",
       "        (u'\\u5929',   2.32239217e-02), ..., (u'\\u75db',   7.86949030e-08),\n",
       "        (u'\\u59ec',   7.86347343e-08), (u'\\u3000',   7.70102986e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u738b',   3.93675603e-02), (u'\\u4faf',   1.52511653e-02),\n",
       "        (u'\\u4eba',   1.43742710e-02), ..., (u'\\u8c08',   3.43167663e-08),\n",
       "        (u'\\u6cc9',   3.43167663e-08), (u'\\u8a89',   3.43167663e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6587',   2.41017547e-02), (u'\\u672c',   2.35150568e-02),\n",
       "        (u'\\u4e66',   2.31483728e-02), ..., (u'\\u60a3',   5.23548422e-08),\n",
       "        (u'\\u62c2',   5.23348618e-08), (u'\\u51a5',   5.23148778e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   2.10216213e-02), (u'\\u6c11',   1.80866010e-02),\n",
       "        (u'\\u5929',   1.61350146e-02), ..., (u'\\u7678',   2.54539252e-08),\n",
       "        (u'\\u5934',   2.54442067e-08), (u'\\u56f4',   2.53858925e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5c71',   3.43977399e-02), (u'\\u5341',   2.55139004e-02),\n",
       "        (u'\\u4e1c',   2.46226713e-02), ..., (u'\\u76c8',   9.46871950e-08),\n",
       "        (u'\\u653f',   9.46148617e-08), (u'\\u79bd',   9.46148617e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   2.96049751e-02), (u'\\u541b',   2.03464124e-02),\n",
       "        (u'\\u53ef',   1.33574223e-02), ..., (u'\\u97e9',   2.95355225e-08),\n",
       "        (u'\\u6545\\u4e8b',   2.95129752e-08), (u'\\u57ce',   2.94904297e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6c64',   2.68273242e-02), (u'\\u4e00',   2.07225215e-02),\n",
       "        (u'\\u5347',   2.03090478e-02), ..., (u'\\u5510',   2.42621724e-07),\n",
       "        (u'\\u795e',   2.42343361e-07), (u'\\u3000',   2.37518762e-07)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u664b',   2.26491448e-02), (u'\\u4eba',   2.17277929e-02),\n",
       "        (u'\\u4faf',   2.08111908e-02), ..., (u'\\u7eaf',   4.74119020e-08),\n",
       "        (u'\\u90e8',   4.74119020e-08), (u'\\u529d',   4.73937867e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u738b',   2.82079987e-02), (u'\\u5929',   2.42411792e-02),\n",
       "        (u'\\u793c',   1.43716484e-02), ..., (u'\\u6ce2',   4.99573254e-08),\n",
       "        (u'\\u6e20',   4.99191586e-08), (u'\\u9634',   4.96138455e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5229',   1.03856046e-02), (u'\\u4eba',   8.76106322e-03),\n",
       "        (u'\\u8c61',   8.29690881e-03), ..., (u'\\u730e',   1.44857964e-07),\n",
       "        (u'\\u6885',   1.44857964e-07), (u'\\u90c1',   1.44747304e-07)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5c06',   2.71455962e-02), (u'\\u519b',   2.22872980e-02),\n",
       "        (u'\\u5175',   1.85539275e-02), ..., (u'\\u64c5',   4.90775989e-08),\n",
       "        (u'\\u8fa9',   4.90588583e-08), (u'\\u7978',   4.90588583e-08)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u4eba',   3.05130333e-02), (u'\\u4e3b',   2.41580866e-02),\n",
       "        (u'\\u62dc',   2.31242664e-02), ..., (u'\\u4e60',   1.51774813e-07),\n",
       "        (u'\\u667a',   1.51716819e-07), (u'\\u6559',   1.51716819e-07)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.topics(print_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Document-topic probabilities\n",
    "The above code shows the topic-word distributions and allows us to estimate the quality of our topics.\n",
    "\n",
    "#### `v.labels`\n",
    "The property `v.labels` (without parentheses) returns a list of all documents in a corpus, and is useful for processing each document generically, wihtout having to look up the identifiers on the file system.\n",
    "\n",
    "Below, we print the first 3 document labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmx/道家/鬻子/鬻子.txt\n",
      "kmx/道家/文始真经/三极.txt\n",
      "kmx/道家/文始真经/九药.txt\n"
     ]
    }
   ],
   "source": [
    "for label in v.labels[:3]:\n",
    "    print label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `v.doc_topics(doc_or_docs)`\n",
    "Each document-topic distribution can be examined with `v.doc_topics()`, which takes as its argument either a single label or a list of labels. Below we view the distribution for the first 3 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe9 in position 9: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/home/hongliang/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hongliang/anaconda2/lib/python2.7/site-packages/vsm/viewer/labeleddata.pyc\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html_compact_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubcolhdr_compact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html_full_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubcolhdr_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hongliang/anaconda2/lib/python2.7/site-packages/vsm/viewer/labeleddata.pyc\u001b[0m in \u001b[0;36m_repr_html_full_\u001b[0;34m(self, subcol_headers)\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mth\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-align: center; background: #CEE3F6;\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                  \u001b[0mcolspan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{0}\"\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_arr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe9 in position 9: ordinal not in range(128)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LabeledColumn([(11,   4.01154935e-01), (13,   1.46559849e-01),\n",
       "        ( 4,   1.26689017e-01), (16,   9.31569785e-02),\n",
       "        (12,   9.06731188e-02), ( 9,   7.08022863e-02),\n",
       "        ( 2,   7.08022863e-02), (18,   1.24314010e-05),\n",
       "        ( 8,   1.24314010e-05), ( 5,   1.24219259e-05),\n",
       "        (10,   1.24219259e-05), ( 6,   1.24219259e-05),\n",
       "        ( 1,   1.24195567e-05), ( 3,   1.24195567e-05),\n",
       "        (19,   1.24195567e-05), ( 7,   1.24195567e-05),\n",
       "        (14,   1.24195567e-05), (15,   1.24195567e-05),\n",
       "        (17,   1.24195567e-05), ( 0,   1.24195567e-05)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')]),\n",
       " LabeledColumn([( 2,   7.66495883e-01), ( 6,   1.26172319e-01),\n",
       "        (11,   5.95215410e-02), (17,   4.76196073e-02),\n",
       "        (13,   1.19135484e-05), (18,   1.19135484e-05),\n",
       "        (16,   1.19044680e-05), (12,   1.19044680e-05),\n",
       "        ( 8,   1.19044680e-05), (19,   1.19021979e-05),\n",
       "        ( 7,   1.19021979e-05), ( 4,   1.19021979e-05),\n",
       "        ( 9,   1.19021979e-05), (10,   1.19021979e-05),\n",
       "        (14,   1.19021979e-05), (15,   1.19021979e-05),\n",
       "        ( 0,   1.19021979e-05), ( 5,   1.19019141e-05),\n",
       "        ( 3,   1.19019141e-05), ( 1,   1.19019141e-05)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')]),\n",
       " LabeledColumn([( 2,   7.21414506e-01), (11,   1.24577537e-01),\n",
       "        (17,   6.82517216e-02), ( 6,   5.20038903e-02),\n",
       "        (14,   3.35896835e-02), (16,   1.08424647e-05),\n",
       "        (13,   1.08424647e-05), (10,   1.08424647e-05),\n",
       "        (19,   1.08321346e-05), ( 1,   1.08321346e-05),\n",
       "        ( 3,   1.08321346e-05), ( 4,   1.08321346e-05),\n",
       "        ( 5,   1.08321346e-05), ( 9,   1.08321346e-05),\n",
       "        ( 7,   1.08321346e-05), ( 8,   1.08321346e-05),\n",
       "        (18,   1.08321346e-05), (12,   1.08321346e-05),\n",
       "        (15,   1.08321346e-05), ( 0,   1.08321346e-05)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.doc_topics(v.labels[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `v.aggregate_doc_topics(doc_or_docs, normed_sum=False)`\n",
    "While `v.doc_topics(doc_or_docs)` shows the distribution for each document, `v.aggregate_doc_topics()` shows the average distribution of a collection of documents. The `normed` argument tells the program whether to weight each document by its length (`normed_sum=True`) or to consider them all equally (`normed_sum=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan                    =\"2\">Aggregate Distribution over Topics</th></tr><tr><th style=\"text-align: center; background: #EFF2FB; \">Topic                          </th><th style=\"text-align: center; background: #EFF2FB; \">Prob                          </th></tr><tr><td>2                                      </td><td>0.51957                                </td></tr><tr><td>11                                     </td><td>0.19508                                </td></tr><tr><td>6                                      </td><td>0.05940                                </td></tr><tr><td>13                                     </td><td>0.04886                                </td></tr><tr><td>4                                      </td><td>0.04224                                </td></tr><tr><td>17                                     </td><td>0.03863                                </td></tr><tr><td>16                                     </td><td>0.03106                                </td></tr><tr><td>12                                     </td><td>0.03023                                </td></tr><tr><td>9                                      </td><td>0.02361                                </td></tr><tr><td>14                                     </td><td>0.01120                                </td></tr></table>"
      ],
      "text/plain": [
       "LabeledColumn([( 2,   5.19570947e-01), (11,   1.95084691e-01),\n",
       "       ( 6,   5.93962185e-02), (13,   4.88608778e-02),\n",
       "       ( 4,   4.22372557e-02), (17,   3.86279188e-02),\n",
       "       (16,   3.10599115e-02), (12,   3.02319545e-02),\n",
       "       ( 9,   2.36083418e-02), (14,   1.12046693e-02),\n",
       "       (18,   1.17256968e-05), ( 8,   1.17226700e-05),\n",
       "       (10,   1.17221971e-05), ( 5,   1.17186582e-05),\n",
       "       (19,   1.17179643e-05), ( 7,   1.17179643e-05),\n",
       "       (15,   1.17179643e-05), ( 0,   1.17179643e-05),\n",
       "       ( 3,   1.17178697e-05), ( 1,   1.17178697e-05)], \n",
       "      dtype=[('i', '<i8'), ('value', '<f4')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.aggregate_doc_topics(v.labels[:3], normed_sum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing documents with `v.dist()`\n",
    "\n",
    "Topic models give us a way to compare the siimilarity between two documents. To do this, we use `v.dist()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83447499227540445"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.dist(v.labels[0], v.labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative distance measures\n",
    "By default, the Topic Explorer uses the Jensen-Shannon Distance to calculate the distance between documents. The Jensen-Shannon Distance (JSD) is a symmetric measure based on information theory that characterizes the difference between two probability distributions.\n",
    "\n",
    "However, several alternate methods are built into the `vsm.spatial` module. These include the Kullbeck-Liebler Divergence, which is an asymmetric component of the JSD and is used in [Murdock et al. (in review)](http://arxiv.org/abs/1509.07175) to characterize the cognitive surprise of a new text, given previous texts.\n",
    "\n",
    "Rather than using the JSD and assuming symmetric divergence between items, we assume that the second document is encountered after the first, effectively measuring text-to-text divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First to second 7.80856329679\n",
      "Second to first 4.71564448494\n"
     ]
    }
   ],
   "source": [
    "# first import KL divergence:\n",
    "from vsm.spatial import KL_div\n",
    "\n",
    "# calculate KL divergence from the first document to the second\n",
    "print \"First to second\", v.dist(v.labels[0], v.labels[1], dist_fn=KL_div)\n",
    "\n",
    "# calculate KL divergence from the second document to the first, highlighting asymmetry:\n",
    "print \"Second to first\", v.dist(v.labels[1], v.labels[0], dist_fn=KL_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python's Help System\n",
    "\n",
    "There are many other functions in the InPhO Topic Explorer and the associated `vsm` library. These are extensively documented within the code. \n",
    "\n",
    "One little-known feature about Python is its capacity for introspection: by using the `help()` method, one can find out all methods and properties of an object. For example, if one wanted to know what methods could be called on their corpus object, you could run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Corpus in module vsm.corpus.base object:\n",
      "\n",
      "class Corpus(BaseCorpus)\n",
      " |  The goal of the Corpus class is to provide an efficient representation    of a textual corpus.\n",
      " |  \n",
      " |  A Corpus object contains an integer representation of the text and\n",
      " |  maps to permit conversion between integer and string\n",
      " |  representations of a given word.\n",
      " |  \n",
      " |  As a BaseCorpus object, it includes a dictionary of tokenizations\n",
      " |  of the corpus and a method for viewing (without copying) these\n",
      " |  tokenizations. This dictionary also stores metadata (e.g.,\n",
      " |  document names) associated with the available tokenizations.\n",
      " |  \n",
      " |  :param corpus: A string array representing the corpus as a sequence of\n",
      " |      atomic words.\n",
      " |  :type corpus: array-like\n",
      " |  \n",
      " |  :param context_data: Each element in `context_data` is an array containing \n",
      " |      the indices marking the token boundaries. An element in `context_data` is\n",
      " |      intended for use as a value for the `indices_or_sections`\n",
      " |      parameter in `numpy.split`. Elements of `context_data` may also be\n",
      " |      1-D arrays whose elements are pairs, where the first element\n",
      " |      is a context boundary and the second element is metadata\n",
      " |      associated with that context preceding that boundary. For\n",
      " |      example, (250, 'dogs') might indicate that the 'article' context\n",
      " |      ending at the 250th word of the corpus is named 'dogs'.\n",
      " |      Default is `None`.\n",
      " |  :type context_data: list-like with 1-D integer array-like elements, optional\n",
      " |  \n",
      " |  :param context_types: Each element in `context_types` is a type of a context\n",
      " |      in `context_data`.\n",
      " |  :type context_types: array-like, optional\n",
      " |  \n",
      " |  :attributes: \n",
      " |      * **corpus** (1-D 32-bit integer array)\n",
      " |          corpus is the integer representation of the input string array-like\n",
      " |          value of the corpus parameter\n",
      " |      * **words** (1-D string array)\n",
      " |          The indexed set of strings occurring in corpus. It is a string-typed array.\n",
      " |      * **words_in** (1-D 32-bit integer dictionary)\n",
      " |          A dictionary whose keys are `words` and whose values are their \n",
      " |          corresponding integers (i.e., indices in `words`).\n",
      " |      \n",
      " |  :methods:\n",
      " |      * **view_metadata**\n",
      " |          Takes a type of tokenization and returns a view of the metadata\n",
      " |          of the tokenization.\n",
      " |      * **view_contexts**\n",
      " |          Takes a type of tokenization and returns a view of the corpus tokenized\n",
      " |          accordingly. The optional parameter `strings` takes a boolean value: \n",
      " |          True to view string representations of words; False to view integer \n",
      " |          representations of words. Default is `False`.\n",
      " |      * **save**\n",
      " |          Takes a filename and saves the data contained in a Corpus object to \n",
      " |          a `npy` file using `numpy.savez`.\n",
      " |      * **load**\n",
      " |          Static method. Takes a filename, loads the file data into a Corpus\n",
      " |          object and returns the object.\n",
      " |      * **apply_stoplist**\n",
      " |          Takes a list of stopwords and returns a copy of the corpus with \n",
      " |          the stopwords removed.\n",
      " |      * **tolist**\n",
      " |          Returns Corpus object as a list of lists of either integers or strings, \n",
      " |          according to `as_strings`.\n",
      " |      \n",
      " |  :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  **Examples**\n",
      " |  \n",
      " |  >>> text = ['I', 'came', 'I', 'saw', 'I', 'conquered']\n",
      " |  >>> context_types = ['sentences']\n",
      " |  >>> context_data = [np.array([(2, 'Veni'), (4, 'Vidi'), (6, 'Vici')],\n",
      " |                          dtype=[('idx', '<i8'), ('sent_label', '|S6')])]\n",
      " |  \n",
      " |  >>> from vsm.corpus import Corpus\n",
      " |  >>> c = Corpus(text, context_types=context_types, context_data=context_data)\n",
      " |  >>> c.corpus\n",
      " |  array([0, 1, 0, 2, 0, 3], dtype=int32)\n",
      " |  \n",
      " |  >>> c.words\n",
      " |  array(['I', 'came', 'saw', 'conquered'],\n",
      " |        dtype='|S9')\n",
      " |  \n",
      " |  >>> c.words_int['saw']\n",
      " |  2\n",
      " |  \n",
      " |  >>> c.view_contexts('sentences')\n",
      " |  [array([0, 3], dtype=int32), array([0, 2], dtype=int32),\n",
      " |   array([0, 1], dtype=int32)]\n",
      " |  \n",
      " |  >>> c.view_contexts('sentences', as_strings=True)\n",
      " |  [array(['I', 'came'], \n",
      " |        dtype='|S9'),\n",
      " |   array(['I', 'saw'], \n",
      " |        dtype='|S9'),\n",
      " |   array(['I', 'conquered'], \n",
      " |        dtype='|S9')]\n",
      " |  \n",
      " |  >>> c.view_metadata('sentences')[1]['sent_label']\n",
      " |  'Vidi'\n",
      " |  \n",
      " |  >>> c = c.apply_stoplist(['saw'])\n",
      " |  >>> c.words\n",
      " |  array(['I', 'came', 'conquered'], \n",
      " |    dtype='|S9')\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Corpus\n",
      " |      BaseCorpus\n",
      " |      future.types.newobject.newobject\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __init__(self, corpus, context_types=[], context_data=[], remove_empty=True)\n",
      " |  \n",
      " |  apply_stoplist(self, stoplist=[], freq=0)\n",
      " |      Takes a Corpus object and returns a copy of it with words in the\n",
      " |      stoplist removed and with words of frequency <= `freq` removed.\n",
      " |      \n",
      " |      :param stoplist: The list of words to be removed.\n",
      " |      :type stoplist: list\n",
      " |      \n",
      " |      :param freq: A threshold where words of frequency <= 'freq' are\n",
      " |          removed. Default is 0.\n",
      " |      :type freq: integer, optional\n",
      " |          \n",
      " |      :returns: Copy of corpus with words in the stoplist and words\n",
      " |          of frequnecy <= 'freq' removed.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`\n",
      " |  \n",
      " |  in_place_stoplist(self, stoplist=None, freq=0)\n",
      " |      Changes a Corpus object with words in the stoplist removed and with \n",
      " |      words of frequency <= `freq` removed.\n",
      " |      \n",
      " |      :param stoplist: The list of words to be removed.\n",
      " |      :type stoplist: list\n",
      " |      \n",
      " |      :param freq: A threshold where words of frequency <= 'freq' are\n",
      " |          removed. Default is 0.\n",
      " |      :type freq: integer, optional\n",
      " |          \n",
      " |      :returns: Copy of corpus with words in the stoplist and words\n",
      " |          of frequnecy <= 'freq' removed.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`\n",
      " |  \n",
      " |  save = wrapper(*args, **kwargs)\n",
      " |  \n",
      " |  tolist(self, context_type, as_strings=False)\n",
      " |      Returns Corpus object as a list of lists of either integers or\n",
      " |      strings, according to `as_strings`.\n",
      " |      \n",
      " |      :param context_type: The type of tokenization.\n",
      " |      :type context_type: string\n",
      " |      \n",
      " |      :param as_strings: If True, string representations of words are returned.\n",
      " |          Otherwise, integer representations are returned. Default\n",
      " |          is `False`.\n",
      " |      :type as_strings: Boolean, optional\n",
      " |      \n",
      " |      :returns: List of lists\n",
      " |  \n",
      " |  view_contexts(self, ctx_type, as_strings=False, as_slices=False, as_indices=False)\n",
      " |      Displays a tokenization of the corpus.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param as_strings: If True, string representations of words are returned.\n",
      " |          Otherwise, integer representations are returned. Default\n",
      " |          is `False`.\n",
      " |      :type as_strings: Boolean, optional\n",
      " |      \n",
      " |      :param as_slices: If True, a list of slices corresponding to 'ctx_type'\n",
      " |          is returned. Otherwise, integer representations are returned.\n",
      " |          Default is `False`.\n",
      " |      :type as_slices: Boolean, optional\n",
      " |      \n",
      " |      :returns: A tokenized view of `corpus`.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`, :class:`BaseCorpus`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  load(file=None, corpus_dir=None, corpus_file='corpus.npy', words_file='words.npy', metadata_file='metadata.npy')\n",
      " |      Loads data into a Corpus object. \n",
      " |      \n",
      " |      :param file: The file to read. See `numpy.load` for further\n",
      " |          details. Assumes file has been constructed as by\n",
      " |          `Corpus.save`. This option is exclusive of `corpus_dir`.\n",
      " |      :type file: str-like or file object\n",
      " |      \n",
      " |      :param corpus_dir: A directory containing the files\n",
      " |      `corpus_file`, `words_file`, `metadata_file`, from which to\n",
      " |      instantiate a Corpus object. This option is ignored if `file`\n",
      " |      is not `None`.\n",
      " |      :type corpus_dir: string\n",
      " |      \n",
      " |      :param corpus_file: File under `corpus_dir` containing the\n",
      " |      corpus data, stored as a numpy array of integers in an `npy`\n",
      " |      file.\n",
      " |      :type corpus_file: string or file object\n",
      " |      \n",
      " |      :param words_file: File under `corpus_dir` containing the\n",
      " |      corpus vocabulary, stored as a numpy array of strings in an\n",
      " |      `npy` file.  \n",
      " |      :type words_file: string or file object\n",
      " |      \n",
      " |      :param metadata_file: File under `corpus_dir` containing the\n",
      " |      corpus metadata, stored as a numpy stuctured array in an `npy`\n",
      " |      file. Note that this structured array should contain a file\n",
      " |      `idx` which stores the integer indices marking the document\n",
      " |      boundaries.\n",
      " |      :type corpus_file: string or file object\n",
      " |      \n",
      " |      :returns: A Corpus object.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`, :meth:`Corpus.save`, :meth:`numpy.load`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  context_data\n",
      " |  \n",
      " |  context_types\n",
      " |  \n",
      " |  corpus\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  stopped_words\n",
      " |  \n",
      " |  words\n",
      " |  \n",
      " |  words_int\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCorpus:\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of tokens in the corpus.\n",
      " |      \n",
      " |      :See Also: `len(self.words)` for the number of unique tokens.\n",
      " |  \n",
      " |  get_metadatum(self, ctx_type, query, field)\n",
      " |      Returns the metadatum corresponding to the query and the field.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param query: Dictionary with a key, value being a field, label\n",
      " |          in metadata.\n",
      " |      :type query: dictionary-like\n",
      " |      \n",
      " |      :param field: Field of the metadata\n",
      " |      :type field: string\n",
      " |      \n",
      " |      :returns: The metadatum corresponding to the query and the field.\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  meta_int(self, ctx_type, query)\n",
      " |      Returns the index of the metadata found in the query.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param query: Dictionary with a key, value being a field, label\n",
      " |          in metadata.\n",
      " |      :type query: dictionary-like\n",
      " |      \n",
      " |      :returns: The index of the metadata found in the query.\n",
      " |      \n",
      " |      :raises: KeyError\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  remove_empty(self)\n",
      " |      Removes empty tokenizations, if `Corpus` object is not empty.\n",
      " |  \n",
      " |  view_metadata(self, ctx_type)\n",
      " |      Displays the metadata corresponding to a tokenization of the\n",
      " |      corpus. This method can be used in :class:`Corpus` as well as\n",
      " |      :class:`BaseCorpus`\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :returns: The metadata for a tokenization.\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`, :class:`Corpus`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from future.types.newobject.newobject:\n",
      " |  \n",
      " |  __long__(self)\n",
      " |  \n",
      " |  __native__(self)\n",
      " |      Hook for the future.utils.native() function\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |  \n",
      " |  next(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from future.types.newobject.newobject:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get help on particular methods. For example, there are many arguments to `v.topics()` beyond `print_len`. These can be seen by calling `help(v.topics)` without parentheses after `v.topics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method topics in module vsm.viewer.ldacgsviewer:\n",
      "\n",
      "topics(self, topic_indices=None, sort=None, print_len=10, as_strings=True, compact_view=True, topic_labels=None) method of vsm.viewer.ldacgsviewer.LdaCgsViewer instance\n",
      "    Returns a list of topics estimated by the model. \n",
      "    Each topic is represented by a list of words and the corresponding \n",
      "    probabilities.\n",
      "    \n",
      "    :param topic_indices: List of indices of topics to be\n",
      "        displayed. Default is all topics.\n",
      "    :type topic_indices: list of integers\n",
      "    \n",
      "    :param sort: Topic sort function.\n",
      "    :type sort: string, values are \"entropy\", \"oscillation\", \"index\", \"jsd\",\n",
      "        \"user\" (default if topic_indices set), \"index\" (default)\n",
      "    \n",
      "    :param print_len: Number of words shown for each topic. Default is 10.\n",
      "    :type print_len: int, optional\n",
      "    \n",
      "    :param as_string: If `True`, each topic displays words rather than its\n",
      "        integer representation. Default is `True`.\n",
      "    :type as_string: boolean, optional\n",
      "    \n",
      "    :param compact_view: If `True`, topics are simply represented as\n",
      "        their top `print_len` number of words. Otherwise, topics are\n",
      "        shown as words and their probabilities. Default is `True`.\n",
      "    :type compact_view: boolean, optional       \n",
      "    \n",
      "    :param topic_labels: List of strings that are names that correspond\n",
      "        to the topics in `topic_indices`.\n",
      "    :type topic_labels: list, optional\n",
      "    \n",
      "    :returns: an instance of :class:`DataTable`.\n",
      "        A structured array of topics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(v.topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `help(v.topics())` *with* parentheses will return help for the object reutrned by `v.topics()`, which is a `DataTable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(v.topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to emphasize that this functionality can be used with any python library, including the standard library. For example, one could look at all the functions included in the `math` library by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "help(math.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For emphasis, calling `help(math.log(3))` will return the documentation for `float`. Why? First `math.log(3)` will be evaluated, then `help()` will be called on that result: `help(1.0986122886681098)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(math.log(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `help()` and `?`\n",
    "\n",
    "Alternatively, you can place a `?` before any function to receive help in a separate \"frame\". This allows you to view help while scrolling up and down the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?math.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Examples\n",
    "\n",
    "This notebook gives some basic building blocks for using the Topic Explorer. Additional examples can be found on GitHub in the [inpho/vsm-demo-notebooks repository](http://github.com/inpho/vsm-demo-notebooks).\n",
    "\n",
    "# Contact Information\n",
    "If you have additional questions regarding the InPhO Topic Explorer or have comments on this tutorial, please e-mail [tutorial@hypershelf.org](mailto:tutorial@hypershelf.org).\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
